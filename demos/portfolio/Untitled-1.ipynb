{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qmcpy as qp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except ImportError:\n",
    "    !pip install -q yfinance\n",
    "    import yfinance as yf\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import timeit\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make folders `data` and `images`\n",
    "import os\n",
    "data_dir = 'data' + os.sep\n",
    "images_dir = 'images' + os.sep\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2014-01-01'\n",
    "#today = date.today()\n",
    "end_date = '2025-12-13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(tickers, description):\n",
    "    col_names = ['Ticker', 'Company', 'Date', 'Adj Close Price', 'Volume']\n",
    "    rows = []\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        company = description[i]\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        if data.empty:\n",
    "            print(f\"Warning: no data for {ticker}\")\n",
    "            continue\n",
    "        data = data.reset_index()\n",
    "        \n",
    "        # Handle column names robustly (could be MultiIndex or different names)\n",
    "        cols = list(data.columns)\n",
    "        \n",
    "        # Find date column\n",
    "        date_col = next((c for c in cols if 'Date' in str(c) or 'date' in str(c)), cols[0])\n",
    "        \n",
    "        # Find adj close column\n",
    "        adj_col_candidates = [c for c in cols if 'Adj' in str(c)]\n",
    "        if not adj_col_candidates:\n",
    "            adj_col_candidates = [c for c in cols if 'Close' in str(c)]\n",
    "        \n",
    "        # Find volume column\n",
    "        vol_col_candidates = [c for c in cols if 'Volume' in str(c) or 'Vol' in str(c)]\n",
    "        \n",
    "        if not adj_col_candidates or not vol_col_candidates:\n",
    "            raise KeyError(f\"Adj Close or Volume column not found for {ticker}. Columns: {cols}\")\n",
    "        \n",
    "        adj_col_sel = adj_col_candidates[0]\n",
    "        vol_col_sel = vol_col_candidates[0]\n",
    "        \n",
    "        # Select and rename columns\n",
    "        data = data[[date_col, adj_col_sel, vol_col_sel]].copy()\n",
    "        data.insert(0, 'Company', company)\n",
    "        data.insert(0, 'Ticker', ticker)\n",
    "        data.columns = col_names\n",
    "        rows.append(data)\n",
    "    \n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_ret(df):\n",
    "    stocks = df.pivot(index='Date', columns='Ticker', values='Adj Close Price')\n",
    "    log_ret = np.log(stocks/stocks.shift(1))\n",
    "\n",
    "    return log_ret.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_weights(sampler_type, n_tickers, n_ports, seed=42):\n",
    "    \"\"\"\n",
    "    Generate portfolio weights using specified sampling method.\n",
    "    \n",
    "    Parameters:\n",
    "        sampler_type: str - 'lattice', 'sobol', 'halton', or 'iid'\n",
    "        n: int - number of assets (dimension)\n",
    "        num_ports: int - number of portfolios to generate\n",
    "        seed: int - random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        weights: ndarray of shape (num_ports, n) with rows summing to 1\n",
    "    \"\"\"\n",
    "    if sampler_type == 'lattice':\n",
    "        sampler = qp.Lattice(dimension=n_tickers, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    elif sampler_type == 'sobol':\n",
    "        sampler = qp.Sobol(dimension=n_tickers, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    elif sampler_type == 'halton':\n",
    "        sampler = qp.Halton(dimension=n_tickers, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    elif sampler_type == 'iid':\n",
    "        sampler = qp.IIDStdUniform(dimension=n_tickers, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sampler type: {sampler_type}. Use 'lattice', 'sobol', 'halton', or 'iid'.\")\n",
    "    \n",
    "    # Normalize weights to sum to 1 (simplex projection)\n",
    "    weights /= weights.sum(axis=1, keepdims=True)\n",
    "    return weights\n",
    "\n",
    "# Legacy functions for backward compatibility\n",
    "def gen_weights_lattice(n_tickers, n_ports):\n",
    "    return gen_weights('lattice', n_tickers, n_ports)\n",
    "\n",
    "def gen_weights_sobol(n_tickers, n_ports):\n",
    "    return gen_weights('sobol', n_tickers, n_ports)\n",
    "\n",
    "def gen_weights_halton(n_tickers, n_ports):\n",
    "    return gen_weights('halton', n_tickers, n_ports)\n",
    "\n",
    "def gen_weights_iid(n_tickers, n_ports):\n",
    "    return gen_weights('iid', n_tickers, n_ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_weights_reps(sampler_type, n_tickers, n_ports, replications, seed=42):\n",
    "\n",
    "    if sampler_type == 'lattice':\n",
    "        sampler = qp.Lattice(dimension=n_tickers, replications=replications, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    elif sampler_type == 'sobol':\n",
    "        sampler = qp.Sobol(dimension=n_tickers, replications=replications, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    elif sampler_type == 'halton':\n",
    "        sampler = qp.Halton(dimension=n_tickers, replications=replications, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    elif sampler_type == 'iid':\n",
    "        sampler = qp.IIDStdUniform(dimension=n_tickers, replications=replications, seed=seed)\n",
    "        weights = sampler.gen_samples(n_ports)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sampler type: {sampler_type}. Use 'lattice', 'sobol', 'halton', or 'iid'.\")\n",
    "    \n",
    "    # Normalize weights to sum to 1 (simplex projection)\n",
    "    weights /= weights.sum(axis=2, keepdims=True)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe(weights,log_ret):\n",
    "    # Expected return\n",
    "    ret_arr = np.sum((log_ret.mean().values * weights * 252), axis=1)\n",
    "\n",
    "    # Expected volatility\n",
    "    vol_arr = np.sqrt((weights @ (log_ret.cov().values * 252)) @ weights.T).diagonal()\n",
    "\n",
    "    # Sharpe Ratio\n",
    "    sharpe_arr = ret_arr/vol_arr\n",
    "\n",
    "    # Risk levels\n",
    "    medium_risk_tolerance = np.quantile(vol_arr, 2/3, axis=0)\n",
    "    low_risk_tolerance = np.quantile(vol_arr, 1/3, axis=0)\n",
    "\n",
    "    medium_risk_idx = np.where(vol_arr<medium_risk_tolerance)\n",
    "    low_risk_idx = np.where(vol_arr<low_risk_tolerance)\n",
    "    \n",
    "    # High risk\n",
    "    high_idx = sharpe_arr.argmax()\n",
    "\n",
    "    # Medium risk\n",
    "    medium_rel_idx = sharpe_arr[medium_risk_idx].argmax()\n",
    "    medium_idx = medium_risk_idx[0][medium_rel_idx]\n",
    "\n",
    "    # Low risk\n",
    "    low_rel_idx = sharpe_arr[low_risk_idx].argmax() \n",
    "    low_idx = low_risk_idx[0][low_rel_idx]\n",
    "\n",
    "    return {\n",
    "        \"number of tickers\": weights.shape[1],\n",
    "        \"number of portfolios\": weights.shape[0],\n",
    "\n",
    "        \"low\": np.round(weights[low_idx], 3).tolist(),\n",
    "        \"medium\": np.round(weights[medium_idx], 3).tolist(),\n",
    "        \"high\": np.round(weights[high_idx], 3).tolist(),\n",
    "\n",
    "        \"low risk Sharpe\": np.round(sharpe_arr[low_idx], 3),\n",
    "        \"medium risk Sharpe\": np.round(sharpe_arr[medium_idx], 3),\n",
    "        \"high risk Sharpe\": np.round(sharpe_arr[high_idx], 3),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23296728, 0.16628356, 0.41561624, 0.18513292],\n",
       "        [0.0131603 , 0.38609054, 0.19580926, 0.4049399 ],\n",
       "        [0.43946917, 0.07226425, 0.39184246, 0.09642413],\n",
       "        [0.15773506, 0.35399836, 0.11010835, 0.37815823],\n",
       "        [0.32346945, 0.37202572, 0.15824971, 0.14625512],\n",
       "        [0.07652209, 0.12507836, 0.40519707, 0.39320248],\n",
       "        [0.59350848, 0.33005931, 0.04618008, 0.03025213],\n",
       "        [0.26558007, 0.0021309 , 0.37410849, 0.35818054]],\n",
       "\n",
       "       [[0.25702139, 0.12968201, 0.40081513, 0.21248148],\n",
       "        [0.09447934, 0.55091168, 0.33446479, 0.02014419],\n",
       "        [0.44676378, 0.03686426, 0.37595509, 0.14041687],\n",
       "        [0.19612041, 0.28750763, 0.12531172, 0.39106024],\n",
       "        [0.34132723, 0.31117189, 0.16703896, 0.18046192],\n",
       "        [0.11859681, 0.08844147, 0.38976938, 0.40319234],\n",
       "        [0.02179448, 0.60217425, 0.16778868, 0.20824259],\n",
       "        [0.18807254, 0.34556848, 0.22769056, 0.23866841]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler_type = 'lattice'\n",
    "n_tickers = 4\n",
    "n_ports = 2**3\n",
    "replications = 2\n",
    "weights_r = gen_weights_reps(sampler_type, n_tickers, n_ports, replications)\n",
    "#weights_r.shape #(replications, n_ports, n_tickers)\n",
    "weights_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23296728, 0.16628356, 0.41561624, 0.18513292],\n",
       "       [0.0131603 , 0.38609054, 0.19580926, 0.4049399 ],\n",
       "       [0.43946917, 0.07226425, 0.39184246, 0.09642413],\n",
       "       [0.15773506, 0.35399836, 0.11010835, 0.37815823],\n",
       "       [0.32346945, 0.37202572, 0.15824971, 0.14625512],\n",
       "       [0.07652209, 0.12507836, 0.40519707, 0.39320248],\n",
       "       [0.59350848, 0.33005931, 0.04618008, 0.03025213],\n",
       "       [0.26558007, 0.0021309 , 0.37410849, 0.35818054]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23296728, 0.16628356, 0.41561624, 0.18513292],\n",
       "       [0.0131603 , 0.38609054, 0.19580926, 0.4049399 ],\n",
       "       [0.43946917, 0.07226425, 0.39184246, 0.09642413],\n",
       "       [0.15773506, 0.35399836, 0.11010835, 0.37815823],\n",
       "       [0.32346945, 0.37202572, 0.15824971, 0.14625512],\n",
       "       [0.07652209, 0.12507836, 0.40519707, 0.39320248],\n",
       "       [0.59350848, 0.33005931, 0.04618008, 0.03025213],\n",
       "       [0.26558007, 0.0021309 , 0.37410849, 0.35818054]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler_type = 'lattice'\n",
    "n_tickers = 4\n",
    "n_ports = 2**3\n",
    "weights = gen_weights(sampler_type, n_tickers, n_ports)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23296728, 0.16628356, 0.41561624, 0.18513292],\n",
       "       [0.0131603 , 0.38609054, 0.19580926, 0.4049399 ],\n",
       "       [0.43946917, 0.07226425, 0.39184246, 0.09642413],\n",
       "       [0.15773506, 0.35399836, 0.11010835, 0.37815823],\n",
       "       [0.32346945, 0.37202572, 0.15824971, 0.14625512],\n",
       "       [0.07652209, 0.12507836, 0.40519707, 0.39320248],\n",
       "       [0.59350848, 0.33005931, 0.04618008, 0.03025213],\n",
       "       [0.26558007, 0.0021309 , 0.37410849, 0.35818054]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tickers = 4\n",
    "n_ports = 2**3\n",
    "weights = qp.Lattice(dimension=n_tickers,seed=42).gen_samples(n_ports)\n",
    "weights /= weights.sum(axis=1, keepdims=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"AAPL\", \"AMZN\", \"CSCO\", \"IBM\"]\n",
    "description = [\"Apple\", \"Amazon\", \"CISCO\", \"IBM\"]\n",
    "\n",
    "fname = f\"{data_dir}df_{start_date}_to_{end_date}.csv\"\n",
    "p = Path(fname)\n",
    "\n",
    "if p.exists():\n",
    "    df = pd.read_csv(p, parse_dates=['Date'])\n",
    "else:\n",
    "    df = download_data(tickers,description)\n",
    "    df.to_csv(p, index=False)\n",
    "\n",
    "lr = get_log_ret(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.05443389, 0.03389552, 0.05665003, 0.01609407],\n",
       "        [0.00307497, 0.07870134, 0.02668953, 0.03520243],\n",
       "        [0.10268402, 0.01473047, 0.05340958, 0.00838239],\n",
       "        [0.03685553, 0.07215962, 0.01500818, 0.03287424],\n",
       "        [0.07558015, 0.07583434, 0.02157002, 0.01271432],\n",
       "        [0.01787974, 0.02549618, 0.05522986, 0.03418207],\n",
       "        [0.13867602, 0.06727984, 0.00629452, 0.00262989],\n",
       "        [0.06205402, 0.00043437, 0.05099237, 0.03113753]],\n",
       "\n",
       "       [[0.06005425, 0.0264346 , 0.05463259, 0.01847154],\n",
       "        [0.02207554, 0.11229875, 0.04558879, 0.00175118],\n",
       "        [0.10438844, 0.00751447, 0.05124407, 0.01220679],\n",
       "        [0.04582445, 0.05860603, 0.01708045, 0.03399584],\n",
       "        [0.0797527 , 0.0634298 , 0.02276803, 0.015688  ],\n",
       "        [0.0277107 , 0.01802806, 0.05312701, 0.03505051],\n",
       "        [0.00509238, 0.1227482 , 0.02287022, 0.01810305],\n",
       "        [0.04394403, 0.07044126, 0.03103507, 0.02074804]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.mean().values * weights_r * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20780704, 0.21314812, 0.21885933, 0.21298378, 0.22767495,\n",
       "       0.20168237, 0.25325773, 0.20413606])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((weights @ (lr.cov().values * 252)) @ weights.T).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20780704, 0.21314812, 0.21885933, 0.21298378, 0.22767495,\n",
       "       0.20168237, 0.25325773, 0.20413606])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((weights_r[0] @ (lr.cov().values * 252)) @ weights_r[0].T).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20638125, 0.24649686, 0.21675198, 0.20832315, 0.22116523,\n",
       "       0.20132159, 0.24380821, 0.21460271])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((weights_r[1] @ (lr.cov().values * 252)) @ weights_r[1].T).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = weights_r.shape[0]\n",
    "for i in range(r):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qmcpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
