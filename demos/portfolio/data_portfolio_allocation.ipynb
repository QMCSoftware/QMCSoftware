{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except ImportError:\n",
    "    !pip install -q yfinance\n",
    "    import yfinance as yf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data' + os.sep\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2014-01-01'\n",
    "end_date = '2025-12-13'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downalod data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(tickers, description):\n",
    "    col_names = ['Ticker', 'Company', 'Date', 'Adj Close Price', 'Volume']\n",
    "    rows = []\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        company = description[i]\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        if data.empty:\n",
    "            print(f\"Warning: no data for {ticker}\")\n",
    "            continue\n",
    "        data = data.reset_index()\n",
    "        \n",
    "        # Handle column names robustly (could be MultiIndex or different names)\n",
    "        cols = list(data.columns)\n",
    "        \n",
    "        # Find date column\n",
    "        date_col = next((c for c in cols if 'Date' in str(c) or 'date' in str(c)), cols[0])\n",
    "        \n",
    "        # Find adj close column\n",
    "        adj_col_candidates = [c for c in cols if 'Adj' in str(c)]\n",
    "        if not adj_col_candidates:\n",
    "            adj_col_candidates = [c for c in cols if 'Close' in str(c)]\n",
    "        \n",
    "        # Find volume column\n",
    "        vol_col_candidates = [c for c in cols if 'Volume' in str(c) or 'Vol' in str(c)]\n",
    "        \n",
    "        if not adj_col_candidates or not vol_col_candidates:\n",
    "            raise KeyError(f\"Adj Close or Volume column not found for {ticker}. Columns: {cols}\")\n",
    "        \n",
    "        adj_col_sel = adj_col_candidates[0]\n",
    "        vol_col_sel = vol_col_candidates[0]\n",
    "        \n",
    "        # Select and rename columns\n",
    "        data = data[[date_col, adj_col_sel, vol_col_sel]].copy()\n",
    "        data.insert(0, 'Company', company)\n",
    "        data.insert(0, 'Ticker', ticker)\n",
    "        data.columns = col_names\n",
    "        rows.append(data)\n",
    "    \n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_ret(df):\n",
    "    stocks = df.pivot(index='Date', columns='Ticker', values='Adj Close Price')\n",
    "    log_ret = np.log(stocks/stocks.shift(1))\n",
    "\n",
    "    return log_ret.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk-free rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf(start_date, end_date, data_dir=data_dir, ticker=\"^IRX\"):\n",
    "    \"\"\"Get 13-week T-bill (^IRX) data and return annual log risk-free rate.\"\"\"\n",
    "\n",
    "    fname = f\"{data_dir}rf_annual_{start_date}_to_{end_date}.csv\"\n",
    "    p = Path(fname)\n",
    "\n",
    "    if p.exists():\n",
    "        rf_df = pd.read_csv(p, parse_dates=['Date'])\n",
    "    else:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date)\n",
    "        df = df.reset_index()\n",
    "\n",
    "        rate_col = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
    "        df = df[['Date', rate_col]].copy()\n",
    "        df.rename(columns={rate_col: 'annual_rate_pct'}, inplace=True)\n",
    "\n",
    "        df['rf_annual'] = np.log(1 + df['annual_rate_pct'] / 100)\n",
    "\n",
    "        rf_df = df[['Date', 'rf_annual']].dropna()\n",
    "        rf_df.to_csv(p, index=False)\n",
    "\n",
    "    return rf_df.set_index('Date')['rf_annual']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = get_rf(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data(tickers, descriptions, data_dir=data_dir, start_date=start_date, end_date=end_date, n_ports=None):\n",
    "    \"\"\"Download and cache ticker data, return log returns and prices\"\"\"\n",
    "    ticker_str = f\"{len(tickers)}\" if len(tickers) > 4 else \"\"\n",
    "    fname = f\"{data_dir}df{ticker_str}_{start_date}_to_{end_date}.csv\"\n",
    "    p = Path(fname)\n",
    "    \n",
    "    if p.exists():\n",
    "        df = pd.read_csv(p, parse_dates=['Date'])\n",
    "    else:\n",
    "        df = download_data(tickers, descriptions)\n",
    "        df.to_csv(p, index=False)\n",
    "    \n",
    "    lr = get_log_ret(df)\n",
    "    return df, lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and compute log returns for four tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"AAPL\", \"AMZN\", \"CSCO\", \"IBM\"]\n",
    "description = [\"Apple\", \"Amazon\", \"CISCO\", \"IBM\"]\n",
    "\n",
    "df, lr = get_ticker_data(tickers, description)\n",
    "\n",
    "lr.to_csv(f\"{data_dir}log_returns_{start_date}_to_{end_date}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and compute log returns for ten tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers1 = [\"AAPL\", \"AMZN\", \"CSCO\", \"IBM\", \"TSLA\", \"META\", \"ABNB\", \"UPS\", \"NFLX\", \"MRNA\"]\n",
    "description1 = [\"Apple\", \"Amazon\", \"CISCO\", \"IBM\", \"Tesla\", \"Meta\", \"Airbnb\", \"UPS\", \"Netflix\", \"Moderna\"]\n",
    "\n",
    "df1, lr1 = get_ticker_data(tickers1, description1)\n",
    "\n",
    "lr1.to_csv(f\"{data_dir}log_returns10_{start_date}_to_{end_date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and compute log returns for twenty tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers2 = [\"AAPL\", \"AMZN\", \"CSCO\",\"IBM\",\"TSLA\",\"META\",\"ABNB\",\"UPS\",\"NFLX\",\"MRNA\",\"^IXIC\", \"T\",\"GE\",\"FMC\",\"AMC\",\"JPM\",\"DIS\",\"CVX\",\"GOOGL\",\"BA\"]\n",
    "description2 = [\"Apple\", \"Amazon\", \"CISCO\", \"IBM\",\"Tesla\",\"Meta\",\"Airbnb\",\"UPS\",\"Netflix\",\"Moderna\",\"NASDAQ\",\"AT&T\",\"General Electric\",\"FMC\",\"AMC\",\"JPMorgan\",\"Disney\",\"Chevron\",\"Google\",\"Boeing\"]\n",
    "\n",
    "df2, lr2 = get_ticker_data(tickers2, description2)\n",
    "\n",
    "lr2.to_csv(f\"{data_dir}log_returns20_{start_date}_to_{end_date}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qmcpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
