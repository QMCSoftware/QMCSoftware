{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk3gAlCpWnSY"
      },
      "source": [
        "# ML Sensitivity Indices\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QMCSoftware/QMCSoftware/blob/develop/demos/iris.ipynb)\n",
        "\n",
        "This notebook demonstrates QMCPy's support for vectorized sensitivity index computation. We preview this functionality by performing classification of Iris species using a decision tree. The computed sensitivity indices provide insight into input subset importance for a classic machine learning problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcwavefAWnSZ",
        "outputId": "1de0ce93-fd82-4d92-b265-397216582d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# @title Execute this cell to install dependancies\n",
        "try:\n",
        "  import google.colab\n",
        "  import os\n",
        "  !pip install -q qmcpy >> /dev/null\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y_QkIfjlWnSa"
      },
      "outputs": [],
      "source": [
        "from numpy import *\n",
        "from qmcpy import *\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skopt import gp_minimize\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fubm6FE-WnSa"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "We begin by reading in the Iris dataset and providing some basic summary statistics. Our goal will be to predict the Iris class (Setosa, Versicolour, or Virginica) based on Iris attributes (sepal length, sepal width, petal length, and petal width)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FUCIbzVWnSb",
        "outputId": "3e6ba450-6f5a-40c4-9569-24e20d644b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 150 (50 in each of three classes)\n",
            ":Number of Attributes: 4 numeric, predictive attributes and the class\n",
            ":Attribute Information:\n",
            "    - sepal length in cm\n",
            "    - sepal width in cm\n",
            "    - petal length in cm\n",
            "    - petal width in cm\n",
            "    - class:\n",
            "            - Iris-Setosa\n",
            "            - Iris-Versicolour\n",
            "            - Iris-Virginica\n",
            "\n",
            ":Summary Statistics:\n",
            "\n",
            "============== ==== ==== ======= ===== ====================\n",
            "                Min  Max   Mean    SD   Class Correlation\n",
            "============== ==== ==== ======= ===== ====================\n",
            "sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "============== ==== ==== ======= ===== ====================\n",
            "\n",
            ":Missing Attribute Values: None\n",
            ":Class Distribution: 33.3% for each of 3 classes.\n",
            ":Creator: R.A. Fisher\n",
            ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            ":Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. dropdown:: References\n",
            "\n",
            "  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "    Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "    Structure and Classification Rule for Recognition in Partially Exposed\n",
            "    Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "    Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "    on Information Theory, May 1972, 431-433.\n",
            "  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "    conceptual clustering system finds 3 classes in the data.\n",
            "  - Many, many more ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = load_iris()\n",
        "print(data['DESCR'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "sr2HywjbWnSb",
        "outputId": "95338665-30a0-465e-c309-edf3f66f9834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df shape: (150, 5)\n",
            "iris species map: {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   iris type  \n",
              "0        0.0  \n",
              "1        0.0  \n",
              "2        0.0  \n",
              "3        0.0  \n",
              "4        0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1c26d44-5211-44f8-b14a-661d10496d94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>iris type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1c26d44-5211-44f8-b14a-661d10496d94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1c26d44-5211-44f8-b14a-661d10496d94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1c26d44-5211-44f8-b14a-661d10496d94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-133a0ed0-3fdd-45e7-95b6-1e509a378ec8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-133a0ed0-3fdd-45e7-95b6-1e509a378ec8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-133a0ed0-3fdd-45e7-95b6-1e509a378ec8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iris type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8192319205190405,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x = data['data']\n",
        "y = data['target']\n",
        "feature_names = data['feature_names']\n",
        "df = pd.DataFrame(hstack((x,y[:,None])),columns=feature_names+['iris type'])\n",
        "print('df shape:',df.shape)\n",
        "target_names = data['target_names']\n",
        "iris_type_map = {i:target_names[i] for i in range(len(target_names))}\n",
        "print('iris species map:',iris_type_map)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si6HBQIGWnSb",
        "outputId": "ab0651a2-ef0e-4dc4-f305-8662daf9436f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data   (xt) shape: (100, 4)\n",
            "training labels (yt) shape: (100,)\n",
            "testing data    (xv) shape: (50, 4)\n",
            "testing labels  (yv) shape: (50,)\n"
          ]
        }
      ],
      "source": [
        "xt,xv,yt,yv = train_test_split(x,y,test_size=1/3,random_state=7)\n",
        "print('training data   (xt) shape: %s'%str(xt.shape))\n",
        "print('training labels (yt) shape: %s'%str(yt.shape))\n",
        "print('testing data    (xv) shape: %s'%str(xv.shape))\n",
        "print('testing labels  (yv) shape: %s'%str(yv.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOcaWLFdWnSb"
      },
      "source": [
        "## Importance of Decision Tree Hyperparameters\n",
        "\n",
        "We would like to predict Iris species using a Decision Tree (DT) classifier. When initializing a DT, we arrive at the question of how to set hyperparameters such as tree depth or the minimum weight fraction for each leaf. These hyperparameters can greatly effect classification accuracy, so it is worthwhile to consider their importance to determining classification performance.\n",
        "\n",
        "Note that while this notebook uses decision trees and the Iris dataset, the methodology is directly applicable to other datasets and models.\n",
        "\n",
        "We begin this exploration by setting up a hyperparameter domain in which to uniformly sample DT hyperparameter configurations. A helper function and its tie into QMCPy are also created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_5zq7et7WnSc"
      },
      "outputs": [],
      "source": [
        "hp_domain = [\n",
        "    {'name':'max_depth', 'bounds':[1,8]},\n",
        "    {'name':'min_weight_fraction_leaf', 'bounds':[0,.5]}]\n",
        "hpnames = [param['name'] for param in hp_domain]\n",
        "hp_lb = array([param['bounds'][0] for param in hp_domain])\n",
        "hp_ub = array([param['bounds'][1] for param in hp_domain])\n",
        "d = len(hp_domain)\n",
        "def get_dt_accuracy(hparams):\n",
        "    accuracies = zeros(len(hparams))\n",
        "    for i,hparam in enumerate(hparams):\n",
        "        kwargs = {hp_domain[j]['name']:hparam[j] for j in range(d)}\n",
        "        kwargs['max_depth'] = int(kwargs['max_depth'])\n",
        "        dt = DecisionTreeClassifier(random_state=7,**kwargs).fit(xt,yt)\n",
        "        yhat = dt.predict(xv)\n",
        "        accuracies[i] = mean(yhat==yv)\n",
        "    return accuracies\n",
        "cf = CustomFun(\n",
        "    true_measure = Uniform(DigitalNetB2(d,seed=7),lower_bound=hp_lb,upper_bound=hp_ub),\n",
        "    g = get_dt_accuracy,\n",
        "    parallel=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhZN1jHEWnSc"
      },
      "source": [
        "### Average Accuracy\n",
        "\n",
        "Our first goal will be to find the average DT accuracy across the hyperparameter domain. To do so, we perform quasi-Monte Carlo numerical integration to approximate the mean testing accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8NieG8uWnSc"
      },
      "outputs": [],
      "source": [
        "avg_accuracy,data_avg_accuracy = CubQMCNetG(cf,abs_tol=1e-4).integrate()\n",
        "data_avg_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzUGPwzxWnSc"
      },
      "source": [
        "Here we find the average accuracy to be 78.7% using $2^{14}$ samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIJAMH-GWnSc"
      },
      "source": [
        "### Sensitivity Indices\n",
        "\n",
        "Next, we wish to quantify how important individual hyperparameters are to determining testing accuracy. To do this, we compute the sensitivity indices of our hyperparameters. In QMCPy we use the `SensitivityIndices` class to compute these sensitivity indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHv6U2Y6WnSd"
      },
      "outputs": [],
      "source": [
        "si = SensitivityIndices(cf)\n",
        "solution_importance,data_importance = CubQMCNetG(si,abs_tol=2.5e-2).integrate()\n",
        "data_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4ENYO-oWnSd"
      },
      "outputs": [],
      "source": [
        "print('closed sensitivity indices: %s'%str(solution_importance[0].squeeze()))\n",
        "print('total sensitivity indices: %s'%str(solution_importance[1].squeeze()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG5v-lBNWnSd"
      },
      "source": [
        "Looking closer at the output, we see that the second hyperparameter (`min_weight_fraction_leaf`) is more important than the first one (`max_depth`). The closed sensitivity indices measure how much that hyperparameter contributes to testing accuracy variance. The total sensitivity indices measure how much that hyperparameter, or any subset of hyperparameters containing that one contributes to testing accuracy variance. For example, the first closed sensitivity index approximates the variability attributable to {`max_depth`} while the first total sensitivity index approximates the variability attributable to both {`max_depth`} and {`max_depth`,`min_weight_fraction_leaf`}.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxkD8CiIWnSd"
      },
      "source": [
        "### Marginals\n",
        "\n",
        "We may also use QMCPy's support for vectorized quasi-Monte Carlo to compute marginal distributions. This is relatively straightforward to do for the Uniform true measure used here, but caution should be taken when adapting these techniques to distributions without independent marginals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riKBS3IAWnSe"
      },
      "outputs": [],
      "source": [
        "def marginal(x,compute_flags,xpts,bools,not_bools):\n",
        "    n,_ = x.shape\n",
        "    x2 = zeros((n,d),dtype=float)\n",
        "    x2[:,bools] = x\n",
        "    y = zeros((n,len(xpts)),dtype=float)\n",
        "    for k,xpt in enumerate(xpts):\n",
        "        if not compute_flags[k]: continue\n",
        "        x2[:,not_bools] = xpt\n",
        "        y[:,k] = get_dt_accuracy(x2)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdq8DBL7WnSe"
      },
      "outputs": [],
      "source": [
        "fig,ax = pyplot.subplots(nrows=1,ncols=2,figsize=(8,4))\n",
        "nticks = 32\n",
        "xpts01 = linspace(0,1,nticks)\n",
        "for i in range(2):\n",
        "    xpts = xpts01*(hp_ub[i]-hp_lb[i])+hp_lb[i]\n",
        "    bools = array([True if j not in [i] else False for j in range(d)])\n",
        "    def marginal_i(x,compute_flags): return marginal(x,compute_flags,xpts,bools,~bools)\n",
        "    cf = CustomFun(\n",
        "         true_measure = Uniform(DigitalNetB2(1,seed=7),lower_bound=hp_lb[bools],upper_bound=hp_ub[bools]),\n",
        "         g = marginal_i,\n",
        "         dimension_indv = len(xpts),\n",
        "         parallel=False)\n",
        "    sol,data = CubQMCNetG(cf,abs_tol=5e-2).integrate()\n",
        "    ax[i].plot(xpts,sol,'-o',color='m')\n",
        "    ax[i].fill_between(xpts,data.comb_bound_high,data.comb_bound_low,color='c',alpha=.5)\n",
        "    ax[i].set_xlabel(hpnames[i].replace('_',' '))\n",
        "    ax[i].set_ylabel('accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeKOmYKzWnSe"
      },
      "source": [
        "## Bayesian Optimization of Hyperparameters\n",
        "\n",
        "Having explored DT hyperparameter importance, we are now ready to construct our optimal DT. We already have quite a bit of data relating hyperparameter settings to testing accuracy, so we may simply select the best configuration and call this an optimal DT. However, if we are looking to squeeze out even more performance, we may choose to perform Bayesian Optimization which incorporates our past metadata. Sample code is provided below despite not finding an improved configuration for this problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbvpvURnWnSf"
      },
      "outputs": [],
      "source": [
        "x0 = data_avg_accuracy.xfull*(hp_ub-hp_lb)+hp_lb\n",
        "y0 = -data_avg_accuracy.yfull.squeeze()\n",
        "print('best result before BO is %d%% accuracy'%(-100*y0.min()))\n",
        "result = gp_minimize(\n",
        "    func = lambda hparams: get_dt_accuracy(atleast_2d(hparams)).squeeze().item(),\n",
        "    dimensions = [(l,u) for l,u in zip(hp_lb,hp_ub)],\n",
        "    n_calls = 32,\n",
        "    n_initial_points = 0,\n",
        "    x0 = x0[:128].tolist(),\n",
        "    y0 = y0[:128].tolist(),\n",
        "    random_state = 7)\n",
        "xbo_best = result.x\n",
        "ybo_best = -result.fun\n",
        "print('best result from BO is %d%% accuracy'%(100*ybo_best))\n",
        "xbo = array(result.x_iters)\n",
        "ybo = -array(result.func_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSp41WVqWnSf"
      },
      "source": [
        "## Best Decision Tree Analysis\n",
        "\n",
        "Below we print the configuration that rested in the best DT. We also print the optimal accuracy achieved (at this configuration) and visualize the branches of this tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrIa8imSWnSf"
      },
      "outputs": [],
      "source": [
        "best_kwargs = {name:val for name,val in zip(hpnames,xbo_best)}\n",
        "best_kwargs['max_depth'] = int(best_kwargs['max_depth'])\n",
        "print(best_kwargs)\n",
        "dt = DecisionTreeClassifier(random_state=7,**best_kwargs).fit(xt,yt)\n",
        "yhat = dt.predict(xv)\n",
        "accuracy = mean(yhat==yv)\n",
        "print('best decision tree accuracy: %.1f%%'%(100*accuracy))\n",
        "fig = pyplot.figure(figsize=(10,15))\n",
        "plot_tree(dt,feature_names=feature_names,class_names=target_names,filled=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_oKFgVgWnSf"
      },
      "source": [
        "### Feature Importance\n",
        "\n",
        "With the optimal DT in hand, we may now question how important the Irises features are in determining the class/species. To answer this question, we again perform sensitivity analysis, but this time we select a uniform measure over the domain of Iris features. Our output which we wish to quantify the variance of is now a length 3 vector of class probabilities. How variable is each species classification as a function of each Iris feature?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "bpGVfa8rWnSg"
      },
      "outputs": [],
      "source": [
        "xfeatures = df.to_numpy()\n",
        "xfeatures_low = xfeatures[:,:-1].min(0)\n",
        "xfeatures_high = xfeatures[:,:-1].max(0)\n",
        "d_features = len(xfeatures_low)\n",
        "def dt_pp(t,compute_flags): return dt.predict_proba(t)\n",
        "cf = CustomFun(\n",
        "    true_measure = Uniform(DigitalNetB2(d_features,seed=7),\n",
        "        lower_bound = xfeatures_low,\n",
        "        upper_bound = xfeatures_high),\n",
        "    g = dt_pp,\n",
        "    dimension_indv = 3,\n",
        "    parallel = False)\n",
        "indices = [[0],[1],[2],[3],[0,1],[0,2],[0,3],[1,2],[1,3],[2,3],[1,2,3],[0,2,3],[0,1,2]]\n",
        "si_cf = SobolIndices(cf,indices)\n",
        "solution,data = CubQMCNetG(si_cf,abs_tol=1e-3,n_init=2**10).integrate()\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZFa9hZ1WnSg"
      },
      "source": [
        "While the solution looks unwieldy, it has quite a natural interpretation. The first axis determines whether we are looking at a closed (index 0) or total (index 1) sensitivity index as before. The second axis indexes the subset of features we are testing. The third and final axis is length 3 for the 3 class probabilities we are interested in. For example, `solution[0,2,2]` looks at the closed sensitivity index of our index 2 feature (petal length) for our index 2 probability (virginica) AKA how important is petal length alone to determining if an Iris is virginica.\n",
        "\n",
        "The results indicate that setosa Irises can be completely determined based on petal length while the versicolor and virginica Irises can be completely determined by looking at both petal length and petal width. Interestingly sepal length and sepal width do not contribute significantly to determining species.\n",
        "\n",
        "These insights are not surprising or especially insightful for a decision tree where the tree structure indicates importance and the scores may even be computed directly. However, for more complicated models and datasets, this analysis pipeline may provide advanced insight into both hyperparameter tuning and feature importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDYJTJL9WnSg"
      },
      "outputs": [],
      "source": [
        "print('solution shape:',solution.shape,'\\n')\n",
        "si_closed = solution[0]\n",
        "si_total = solution[1]\n",
        "print('SI Closed')\n",
        "print(si_closed,'\\n')\n",
        "print('SI Total')\n",
        "print(si_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5IRANkHWnSg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
