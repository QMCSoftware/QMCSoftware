{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce064a42",
   "metadata": {},
   "source": [
    "# Vectorized QMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484d4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qmcpy as qp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf10463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qmcpy matplotlib style applied.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "qp.qmc_apply_style()\n",
    "%matplotlib inline\n",
    "root = '../_ags/vec_qmc_out/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "728a1c89",
   "metadata": {},
   "source": [
    "## LD Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabaf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2**6\n",
    "s = 10\n",
    "fig,ax = pyplot.subplots(figsize=(8,4),nrows=1,ncols=3)\n",
    "for i,(dd,name) in enumerate(zip(\n",
    "    [qp.IIDStdUniform(2,seed=7),qp.DigitalNetB2(2,seed=7),qp.Lattice(2,seed=7)],\n",
    "    ['IID','Randomized Digital Net (LD)','Randomized Lattice (LD)'])):\n",
    "    pts = dd.gen_samples(n)\n",
    "    ax[i].scatter(pts[0:n//4,0],pts[0:n//4,1],color='k',marker='s',s=s)\n",
    "    ax[i].scatter(pts[n//4:n//2,0],pts[n//4:n//2,1],color='k',marker='o',s=s)\n",
    "    ax[i].scatter(pts[n//2:n,0],pts[n//2:n,1],color='k',marker='^',s=s)\n",
    "    ax[i].set_aspect(1)\n",
    "    ax[i].set_xlabel(r'$x_{1}$')\n",
    "    ax[i].set_ylabel(r'$x_{2}$')\n",
    "    ax[i].set_xlim([0,1])\n",
    "    ax[i].set_ylim([0,1])\n",
    "    ax[i].set_xticks([0,.25,.5,.75,1])\n",
    "    ax[i].set_xticklabels([r'$0$',r'$1/4$',r'$1/2$',r'$3/4$',r'$1$'])\n",
    "    ax[i].set_yticks([0,.25,.5,.75,1])\n",
    "    ax[i].set_yticklabels([r'$0$',r'$1/4$',r'$1/2$',r'$3/4$',r'$1$'])\n",
    "    ax[i].set_title(name)\n",
    "if root: fig.savefig(root+'ld_seqs.pdf',transparent=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1aa7b935",
   "metadata": {},
   "source": [
    "## Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cantilever_beam_function(T,compute_flags): # T is (n x 3)\n",
    "    Y = np.zeros((len(T),2),dtype=float) # (n x 2)\n",
    "    l,w,t = 100,4,2\n",
    "    T1,T2,T3 = T[:,0],T[:,1],T[:,2] # Python is indexed from 0\n",
    "    if compute_flags[0]: # compute D. x^2 is \"x**2\" in Python\n",
    "        Y[:,0] = 4*l**3/(T1*w*t)*np.sqrt(T2**2/t**4+T3**2/w**4)\n",
    "    if compute_flags[1]: # compute S\n",
    "        Y[:,1] = 600*(T2/(w*t**2)+T3/(w**2*t))\n",
    "    return Y\n",
    "true_measure = qp.Gaussian(\n",
    "    sampler = qp.DigitalNetB2(dimension=3,seed=7),\n",
    "    mean = [2.9e7,500,1000],\n",
    "    covariance = np.diag([(1.45e6)**2,(100)**2,(100)**2]))\n",
    "integrand = qp.CustomFun(true_measure,\n",
    "    g = cantilever_beam_function,\n",
    "    dimension_indv = 2)\n",
    "qmc_stop_crit = qp.CubQMCNetG(integrand,\n",
    "    abs_tol = 1e-3,\n",
    "    rel_tol = 1e-6)\n",
    "solution,data = qmc_stop_crit.integrate()\n",
    "print(solution)\n",
    "# [2.42575885e+00 3.74999973e+04]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4573dad8",
   "metadata": {},
   "source": [
    "## BO QEI\n",
    "\n",
    "See the [QEI Demo in QMCPy](https://qmcpy.readthedocs.io/en/latest/demo_rst/qei-demo-for-blog.html) or the [BoTorch Acquisition documentation](https://botorch.org/docs/acquisition) for details on Bayesian Optimization using q-Expected Improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor,kernels\n",
    "\n",
    "f = lambda x: np.cos(10*x)*np.exp(.2*x)+np.exp(-5*(x-.4)**2)\n",
    "xplt = np.linspace(0,1,100)\n",
    "yplt = f(xplt)\n",
    "x = np.array([.1, .2, .4, .7, .9])\n",
    "y = f(x)\n",
    "ymax = y.max()\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernels.RBF(length_scale=1.0,length_scale_bounds=(1e-2, 1e2)),\n",
    "    n_restarts_optimizer = 16).fit(x[:,None],y)\n",
    "yhatplt,stdhatplt = gp.predict(xplt[:,None],return_std=True)\n",
    "\n",
    "tpax = 32\n",
    "x0mesh,x1mesh = np.meshgrid(np.linspace(0,1,tpax),np.linspace(0,1,tpax))\n",
    "post_mus = np.zeros((tpax,tpax,2),dtype=float)\n",
    "post_sqrtcovs = np.zeros((tpax,tpax,2,2),dtype=float)\n",
    "for j0 in range(tpax):\n",
    "    for j1 in range(tpax):\n",
    "        candidate = np.array([[x0mesh[j0,j1]],[x1mesh[j0,j1]]])\n",
    "        post_mus[j0,j1],post_cov = gp.predict(candidate,return_cov=True)\n",
    "        evals,evecs = scipy.linalg.eig(post_cov)\n",
    "        post_sqrtcovs[j0,j1] = np.sqrt(np.maximum(evals.real,0))*evecs\n",
    "\n",
    "def qei_acq_vec(x,compute_flags):\n",
    "    xgauss = scipy.stats.norm.ppf(x)\n",
    "    n = len(x)\n",
    "    qei_vals = np.zeros((n,tpax,tpax),dtype=float)\n",
    "    for j0 in range(tpax):\n",
    "        for j1 in range(tpax):\n",
    "            if compute_flags[j0,j1]==False: continue\n",
    "            sqrt_cov = post_sqrtcovs[j0,j1]\n",
    "            mu_post = post_mus[j0,j1]\n",
    "            for i in range(len(x)):\n",
    "                yij = sqrt_cov@xgauss[i]+mu_post\n",
    "                qei_vals[i,j0,j1] = max((yij-ymax).max(),0)\n",
    "    return qei_vals\n",
    "\n",
    "qei_acq_vec_qmcpy = qp.CustomFun(\n",
    "    true_measure = qp.Uniform(qp.DigitalNetB2(2,seed=7)),\n",
    "    g = qei_acq_vec,\n",
    "    dimension_indv = (tpax,tpax),\n",
    "    parallel=False)\n",
    "qei_vals,qei_data = qp.CubQMCNetG(qei_acq_vec_qmcpy,abs_tol=.025,rel_tol=0).integrate() # .0005\n",
    "print(qei_data)\n",
    "\n",
    "a = np.unravel_index(np.argmax(qei_vals,axis=None),qei_vals.shape)\n",
    "xnext = np.array([x0mesh[a[0],a[1]],x1mesh[a[0],a[1]]])\n",
    "fnext = f(xnext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5938bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "fig,ax = pyplot.subplots(nrows=1,ncols=2,figsize=(8,3.25))\n",
    "ax[0].scatter(x,y,color='k',label='Query Points')\n",
    "ax[0].plot(xplt,yplt,color='k',linestyle='--',label='True function',linewidth=1)\n",
    "ax[0].plot(xplt,yhatplt,color='k',label='GP Mean',linewidth=1)\n",
    "ax[0].fill_between(xplt,yhatplt-1.96*stdhatplt,yhatplt+1.96*stdhatplt,color='k',alpha=.25,label='95% CI')\n",
    "ax[0].scatter(xnext,fnext,color='k',marker='*',s=200,zorder=10)\n",
    "ax[0].set_xlim([0,1])\n",
    "ax[0].set_xticks([0,1])\n",
    "ax[0].set_xlabel(r'$x$')\n",
    "ax[0].set_ylabel(r'$y$')\n",
    "fig.legend(labels=['data','true function','posterior mean',r'95\\% CI','next points by qEI'],loc='lower center',bbox_to_anchor=(.5,-.05),ncol=5)\n",
    "contour = ax[1].contourf(x0mesh,x1mesh,qei_vals,cmap=cm.Greys_r)\n",
    "ax[1].scatter([xnext[0]],[xnext[1]],color='k',marker='*',s=200)\n",
    "fig.colorbar(contour,ax=None,shrink=1,aspect=5)\n",
    "ax[1].scatter(x0mesh.flatten(),x1mesh.flatten(),color='w',s=1)\n",
    "ax[1].set_xlim([0,1])\n",
    "ax[1].set_xticks([0,1])\n",
    "ax[1].set_ylim([0,1])\n",
    "ax[1].set_yticks([0,1])\n",
    "ax[1].set_xlabel(r'$x_1$')\n",
    "ax[1].set_ylabel(r'$x_2$')\n",
    "if root: fig.savefig(root+'gp.pdf',transparent=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "537cf7f0",
   "metadata": {},
   "source": [
    "## Bayesian Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c109b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data',header=None)\n",
    "df.columns = ['Age','1900 Year','Axillary Nodes','Survival Status']\n",
    "df.loc[df['Survival Status']==2,'Survival Status'] = 0\n",
    "x,y = df[['Age','1900 Year','Axillary Nodes']],df['Survival Status']\n",
    "xt,xv,yt,yv = train_test_split(x,y,test_size=.33,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7372124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(),'\\n')\n",
    "print(df[['Age','1900 Year','Axillary Nodes']].describe(),'\\n')\n",
    "print(df['Survival Status'].astype(str).describe())\n",
    "print('\\ntrain samples: %d test samples: %d\\n'%(len(xt),len(xv)))\n",
    "print('train positives %d   train negatives: %d'%(np.sum(yt==1),np.sum(yt==0)))\n",
    "print(' test positives %d    test negatives: %d'%(np.sum(yv==1),np.sum(yv==0)))\n",
    "xt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc71af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blr = qp.BayesianLRCoeffs(\n",
    "    sampler = qp.DigitalNetB2(4,seed=7),\n",
    "    feature_array = xt, # np.ndarray of shape (n,d-1)\n",
    "    response_vector = yt, # np.ndarray of shape (n,)\n",
    "    prior_mean = 0, # normal prior mean = (0,0,...,0)\n",
    "    prior_covariance = 5) # normal prior covariance = 5I\n",
    "qmc_sc = qp.CubQMCNetG(blr,\n",
    "    abs_tol = .05,\n",
    "    rel_tol = .5,\n",
    "    error_fun = lambda s,abs_tols,rel_tols:\n",
    "        np.minimum(abs_tols,np.abs(s)*rel_tols))\n",
    "blr_coefs,blr_data = qmc_sc.integrate()\n",
    "print(blr_data)\n",
    "# LDTransformData (AccumulateData Object)\n",
    "#     solution        [-0.004  0.13  -0.157  0.008]\n",
    "#     comb_bound_low  [-0.006  0.092 -0.205  0.007]\n",
    "#     comb_bound_high [-0.003  0.172 -0.109  0.012]\n",
    "#     comb_flags      [ True  True  True  True]\n",
    "#     n_total         2^(18)\n",
    "#     n               [[  1024.   1024. 262144.   2048.]\n",
    "#                     [  1024.   1024. 262144.   2048.]]\n",
    "#     time_integrate  2.229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeee8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def metrics(y,yhat):\n",
    "    y,yhat = np.array(y),np.array(yhat)\n",
    "    tp = np.sum((y==1)*(yhat==1))\n",
    "    tn = np.sum((y==0)*(yhat==0))\n",
    "    fp = np.sum((y==0)*(yhat==1))\n",
    "    fn = np.sum((y==1)*(yhat==0))\n",
    "    accuracy = (tp+tn)/(len(y))\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    return [accuracy,precision,recall]\n",
    "\n",
    "results = pd.DataFrame({name:[] for name in ['method','Age','1900 Year','Axillary Nodes','Intercept','Accuracy','Precision','Recall']})\n",
    "for i,l1_ratio in enumerate([0,.5,1]):\n",
    "    lr = LogisticRegression(random_state=7,penalty=\"elasticnet\",solver='saga',l1_ratio=l1_ratio).fit(xt,yt)\n",
    "    results.loc[i] = [r'Elastic-Net \\lambda=%.1f'%l1_ratio]+lr.coef_.squeeze().tolist()+[lr.intercept_.item()]+metrics(yv,lr.predict(xv))\n",
    "\n",
    "blr_predict = lambda x: 1/(1+np.exp(-np.array(x)@blr_coefs[:-1]-blr_coefs[-1]))>=.5\n",
    "blr_train_accuracy = np.mean(blr_predict(xt)==yt)\n",
    "blr_test_accuracy = np.mean(blr_predict(xv)==yv)\n",
    "results.loc[len(results)] = ['Bayesian']+blr_coefs.squeeze().tolist()+metrics(yv,blr_predict(xv))\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',FutureWarning)\n",
    "results.set_index('method',inplace=True)\n",
    "print(results.head())\n",
    "#root: results.to_latex(root+'lr_table.tex',formatters={'%s'%tt:lambda v:'%.1f'%(100*v) for tt in ['accuracy','precision','recall']},float_format=\"%.2e\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1002afa",
   "metadata": {},
   "source": [
    "## Sensitivity Indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c871796",
   "metadata": {},
   "source": [
    "### Ishigami Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e52264",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 7,0.1\n",
    "dnb2 = qp.DigitalNetB2(3,seed=7)\n",
    "ishigami = qp.Ishigami(dnb2,a,b)\n",
    "idxs =[[0], [1], [2], [0,1], [0,2], [1,2]]\n",
    "ishigami_si = qp.SensitivityIndices(ishigami,idxs)\n",
    "qmc_algo = qp.CubQMCNetG(ishigami_si,abs_tol=.05)\n",
    "solution,data = qmc_algo.integrate()\n",
    "print(data)\n",
    "si_closed = solution[0].squeeze()\n",
    "si_total = solution[1].squeeze()\n",
    "ci_comb_low_closed = data.comb_bound_low[0].squeeze()\n",
    "ci_comb_high_closed = data.comb_bound_high[0].squeeze()\n",
    "ci_comb_low_total = data.comb_bound_low[1].squeeze()\n",
    "ci_comb_high_total = data.comb_bound_high[1].squeeze()\n",
    "print(\"\\nApprox took %.1f sec and n = 2^(%d)\"%\n",
    "    (data.time_integrate,np.log2(data.n_total)))\n",
    "print('\\t si_closed:',si_closed)\n",
    "print('\\t si_total:',si_total)\n",
    "print('\\t ci_comb_low_closed:',ci_comb_low_closed)\n",
    "print('\\t ci_comb_high_closed:',ci_comb_high_closed)\n",
    "print('\\t ci_comb_low_total:',ci_comb_low_total)\n",
    "print('\\t ci_comb_high_total:',ci_comb_high_total)\n",
    "\n",
    "true_indices = qp.Ishigami._exact_sensitivity_indices(idxs,a,b)\n",
    "si_closed_true = true_indices[0]\n",
    "si_total_true = true_indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2232e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = pyplot.subplots(figsize=(6,3))\n",
    "ax.grid(False)\n",
    "for spine in ['top','left','right','bottom']: ax.spines[spine].set_visible(False)\n",
    "width = .75\n",
    "ax.errorbar(fmt='none',color='k',\n",
    "    x = 1-si_total_true,\n",
    "    y = np.arange(len(si_closed)),\n",
    "    xerr = 0,\n",
    "    yerr = width/2,\n",
    "    alpha = 1)\n",
    "bar_closed = ax.barh(np.arange(len(si_closed)),np.flip(si_closed),width,label='Closed SI',color='w',edgecolor='k',alpha=.75,linestyle='--')\n",
    "ax.errorbar(fmt='none',color='k',\n",
    "    x = si_closed,\n",
    "    y = np.flip(np.arange(len(si_closed)))+width/4,\n",
    "    xerr = np.vstack((si_closed-ci_comb_low_closed,ci_comb_high_closed-si_closed)),\n",
    "    yerr = 0,\n",
    "    #elinewidth = 5,\n",
    "    alpha = .75)\n",
    "bar_total = ax.barh(np.arange(len(si_closed)),si_total,width,label='Total SI',color='w',alpha=.25,edgecolor='k',left=1-si_total,zorder=10,linestyle='-.')\n",
    "ax.errorbar(fmt='none',color='k',\n",
    "    x = 1-si_total,\n",
    "    y = np.arange(len(si_closed))-width/4,\n",
    "    xerr = np.vstack((si_total-ci_comb_low_total,ci_comb_high_total-si_total)),\n",
    "    yerr = 0,\n",
    "    #elinewidth = 5,\n",
    "    alpha = .25)\n",
    "closed_labels = [r'$\\underline{s}_{\\{%s\\}} = %.2f$'%(','.join([str(i+1) for i in idx]),c) for idx,c in zip(idxs[::-1],np.flip(si_closed))]\n",
    "closed_labels[3] = ''\n",
    "total_labels = [r'$\\overline{s}_{\\{%s\\}} = %.2f$'%(','.join([str(i+1) for i in idx]),t) for idx,t in zip(idxs,si_total)]\n",
    "ax.bar_label(bar_closed,label_type='center',labels=closed_labels)\n",
    "ax.bar_label(bar_total,label_type='center',labels=total_labels)\n",
    "ax.set_xlim([-.001,1.001])\n",
    "ax.axvline(x=0,ymin=0,ymax=len(si_closed),color='k',alpha=.25)\n",
    "ax.axvline(x=1,ymin=0,ymax=len(si_closed),color='k',alpha=.25)\n",
    "ax.set_yticklabels([])\n",
    "if root: fig.savefig(root+'ishigami.pdf',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = pyplot.subplots(nrows=1,ncols=3,figsize=(8,3))\n",
    "x_1d = np.linspace(0,1,num=128)\n",
    "x_1d_mat = np.tile(x_1d,(3,1)).T\n",
    "y_1d = qp.Ishigami._exact_fu_functions(x_1d_mat,indices=[[0],[1],[2]],a=a,b=b)\n",
    "for i in range(2):\n",
    "    ax[i].plot(x_1d,y_1d[:,i],color='k')\n",
    "    ax[i].set_xlim([0,1])\n",
    "    ax[i].set_xticks([0,1])\n",
    "    ax[i].set_xlabel(r'$x_{%d}$'%(i+1))\n",
    "    ax[i].set_title(r'$f_{\\{%d\\}} \\in [%.1f,%.1f]$'%(i+1,y_1d[:,i].min(),y_1d[:,i].max()))\n",
    "x_mesh,y_mesh = np.meshgrid(x_1d,x_1d)\n",
    "xquery = np.zeros((x_mesh.size,3))\n",
    "for i,idx in enumerate([[1,2]]): # [[0,1],[0,2],[1,2]]\n",
    "    xquery[:,idx[0]] = x_mesh.flatten()\n",
    "    xquery[:,idx[1]] = y_mesh.flatten()\n",
    "    zquery = qp.Ishigami._exact_fu_functions(xquery,indices=[idx],a=a,b=b)\n",
    "    z_mesh = zquery.reshape(x_mesh.shape)\n",
    "    ax[2+i].contourf(x_mesh,y_mesh,z_mesh,cmap=cm.Greys_r)\n",
    "    ax[2+i].set_xlabel(r'$x_{%d}$'%(idx[0]+1))\n",
    "    ax[2+i].set_ylabel(r'$x_{%d}$'%(idx[1]+1))\n",
    "    ax[2+i].set_title(r'$f_{\\{%d,%d\\}} \\in [%.1f,%.1f]$'%(tuple([i+1 for i in idx])+(z_mesh.min(),z_mesh.max())))\n",
    "    ax[2+i].set_xlim([0,1])\n",
    "    ax[2+i].set_ylim([0,1])\n",
    "    ax[2+i].set_xticks([0,1])\n",
    "    ax[2+i].set_yticks([0,1])\n",
    "if root: fig.savefig(root+'ishigami_fu.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fc6f6c7",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841067ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "data = load_iris()\n",
    "feature_names = data[\"feature_names\"]\n",
    "feature_names = [fn.replace('sepal ','S')\\\n",
    "    .replace('length ','L')\\\n",
    "    .replace('petal ','P')\\\n",
    "    .replace('width ','W')\\\n",
    "    .replace('(cm)','') for fn in feature_names]\n",
    "target_names = data[\"target_names\"]\n",
    "xt,xv,yt,yv = train_test_split(data[\"data\"],data[\"target\"],\n",
    "    test_size = 1/3,\n",
    "    random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7846bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier(random_state=7,max_iter=1024).fit(xt,yt)\n",
    "yhat = mlpc.predict(xv)\n",
    "print(\"accuracy: %.1f%%\"%(100*(yv==yhat).mean()))\n",
    "# accuracy: 98.0%\n",
    "sampler = qp.DigitalNetB2(4,seed=7)\n",
    "true_measure =  qp.Uniform(sampler,\n",
    "    lower_bound = xt.min(0),\n",
    "    upper_bound = xt.max(0))\n",
    "fun = qp.CustomFun(\n",
    "    true_measure = true_measure,\n",
    "    g = lambda x,compute_flags: mlpc.predict_proba(x),\n",
    "    dimension_indv = 3)\n",
    "si_fun = qp.SensitivityIndices(fun,indices=\"all\")\n",
    "qmc_algo = qp.CubQMCNetG(si_fun,abs_tol=.005)\n",
    "nn_sis,nn_sis_data = qmc_algo.integrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nn_sis_data.flags_indv.shape)\n",
    "#print(nn_sis_data.flags_comb.shape)\n",
    "print('samples: 2^(%d)'%np.log2(nn_sis_data.n_total))\n",
    "print('time: %.1e'%nn_sis_data.time_integrate)\n",
    "print('indices:',nn_sis_data.integrand.indices)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_closed = pd.DataFrame(nn_sis[0],columns=target_names,index=[str(idx) for idx in nn_sis_data.integrand.indices])\n",
    "print('\\nClosed Indices')\n",
    "print(df_closed)\n",
    "df_total = pd.DataFrame(nn_sis[1],columns=target_names,index=[str(idx) for idx in nn_sis_data.integrand.indices])\n",
    "print('\\nTotal Indices')\n",
    "print(df_total)\n",
    "df_closed_singletons = df_closed.T.iloc[:,:4]\n",
    "df_closed_singletons['sum singletons'] = df_closed_singletons[['[%d]'%i for i in range(4)]].sum(1)\n",
    "df_closed_singletons.columns = data['feature_names']+['sum']\n",
    "df_closed_singletons = df_closed_singletons*100\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',FutureWarning)\n",
    "#if root: df_closed_singletons.to_latex(root+'si_singletons_closed.tex',float_format='%.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nindices = len(nn_sis_data.integrand.indices)\n",
    "fig,ax = pyplot.subplots(figsize=(6,3.5))\n",
    "ticks = np.arange(nindices)\n",
    "width = .25\n",
    "for i,(alpha,species) in enumerate(zip([.25,.5,.75],data['target_names'])):\n",
    "    cvals = df_closed[species].to_numpy()\n",
    "    tvals = df_total[species].to_numpy()\n",
    "    ticks_i = ticks+i*width\n",
    "    ax.bar(ticks_i,cvals,width=width,align='edge',color='k',alpha=alpha,label=species)\n",
    "    #ax.bar(ticks_i,np.flip(tvals),width=width,align='edge',bottom=1-np.flip(tvals),color=color,alpha=.1)\n",
    "ax.set_xlim([0,13+3*width])\n",
    "ax.set_xticks(ticks+1.5*width)\n",
    "\n",
    "# closed_labels = [r'$\\underline{s}_{\\{%s\\}}$'%(','.join([r'\\text{%s}'%feature_names[i] for i in idx])) for idx in nn_sis_data.integrand.indices]\n",
    "closed_labels = ['\\n'.join([feature_names[i] for i in idx]) for idx in nn_sis_data.integrand.indices]\n",
    "ax.set_xticklabels(closed_labels,rotation=0)\n",
    "ax.set_ylim([0,1]); ax.set_yticks([0,1])\n",
    "ax.grid(False)\n",
    "for spine in ['top','right','bottom']: ax.spines[spine].set_visible(False)\n",
    "ax.legend(frameon=False,loc='upper center',bbox_to_anchor=(.5,-.2),ncol=3);\n",
    "if root: fig.savefig(root+'nn_si.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebad77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
