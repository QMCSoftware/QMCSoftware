{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Brownian Motion Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QMCSoftware/QMCSoftware/blob/geometric_brownian_motion/demos/gbm_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larysa Matiukha, Aleksei Sorokin, and Sou-Cheng T. Choi\n",
    "\n",
    "Illinois Institute of Technology\n",
    "\n",
    "Modification date: 09/07/2025\n",
    "\n",
    "Creation date: 08/24/2024\n",
    "\n",
    "For reproducibility, this notebook was run with:\n",
    "- Python 3.9.13, NumPy 1.23.4, SciPy 1.9.3, QMCPy 2.1, QuantLib 1.38, Matplotlib 3.5.2, ipywidgets 8.1.7\n",
    "- OS: macOS 15.6.1\n",
    "- Random seeds: 42 (QMCPy), 7 (QuantLib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import qmcpy as qp\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -q qmcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qmcpy as qp\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import latex_util as lu\n",
    "import plot_util as pu\n",
    "import data_util as du\n",
    "import quantlib_util as qlu\n",
    "import qmcpy_util as qpu\n",
    "import config as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric Brownian motion (GBM) is a continuous stochastic process in which the natural logarithm of its values follows a Brownian motion. $[1]$\n",
    "\n",
    "Mathematically, it can be defined as follows:\n",
    "\n",
    "$\\large{S_t = S_0 \\, e^{\\big(\\mu - \\frac{\\sigma^2}{2}\\big)  t + \\sigma W_t}}$, \n",
    "\n",
    "where\n",
    "* $S_0$ is the initial value, \n",
    "* $\\mu$ is a drift coefficient\n",
    "* $\\sigma$ is diffusion coefficient  \n",
    "* $W_t$ is a (standard) Brownian motion.\n",
    "\n",
    "GBM is commonly used to model stock prices and options payoffs. \n",
    "\n",
    "Note that QMCPy uses diffusion = σ² while the mathematical formulation shows σ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM Objects in QMCPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric Brownian Motion in QMCPy inherits from BrownianMotion class $[2, 3]$. \n",
    "\n",
    "Let's explore the constructor and sample generation methods through the built-in help documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(qp.GeometricBrownianMotion.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(qp.GeometricBrownianMotion.gen_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a simple GBM instance and generate sample paths to see the class in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = qp.GeometricBrownianMotion(qp.Lattice(2, seed=42))\n",
    "gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.gen_samples(n=4)  # print four samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Normality Property\n",
    "\n",
    "At any time $t > 0$, $S_t$ follows a log-normal distribution with expected value and variance as follows (see Section 3.2 in $[1]$):\n",
    "\n",
    "- $E[S_t] = S_0 e^{\\mu t}$\n",
    "- $\\text{Var}[S_t] = S_0^2 e^{2\\mu t}(e^{\\sigma^2 t} - 1)$\n",
    "\n",
    "The log-normal property is fundamental in financial modeling because it ensures asset prices remain strictly positive (as required in reality) while allowing for unlimited upside potential. This property makes GBM the cornerstone of the Black-Scholes model and many derivative pricing frameworks.\n",
    "\n",
    "Let's validate these theoretical properties by generating a large number of GBM samples and comparing the empirical moments with the theoretical values. Note that the theoretical values match the last values in `qp_gbm.mean_gbm` and `qp_gbm.covariance_gbm` for the final time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GBM samples for theoretical validation\n",
    "S0, mu, sigma, T, n_samples = 100.0, 0.05, 0.20, 1.0, 2**12\n",
    "diffusion = sigma**2\n",
    "sampler = qp.Lattice(5, seed=42)\n",
    "qp_gbm = qp.GeometricBrownianMotion(sampler, t_final=T, initial_value=S0, drift=mu, diffusion=diffusion)\n",
    "paths = qp_gbm.gen_samples(n_samples)\n",
    "S_T = paths[:, -1]  # Final values only\n",
    "\n",
    "# Calculate theoretical vs empirical sample moments\n",
    "theo_mean = S0 * np.exp(mu * T)\n",
    "theo_var = S0**2 * np.exp(2*mu*T) * (np.exp(diffusion * T) - 1)\n",
    "qp_emp_mean = np.mean(S_T)\n",
    "qp_emp_var = np.var(S_T, ddof=1) \n",
    "print(f\"Mean: {qp_emp_mean:.3f} (theoretical: {theo_mean:.3f})\")\n",
    "print(f\"Variance: {qp_emp_var:.3f} (theoretical: {theo_var:.3f})\")\n",
    "qp_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMB vs Brownian Motion Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compare Brownian motion and geometric Brownian motion using the same parameters: `drift` = 0, `diffusion` = 1, `initial_value` = 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a utility function that will help us visualize GBM paths with different samplers and parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_paths(motion_type, sampler, t_final, initial_value, drift, diffusion, n, png_filename=None):\n",
    "    if motion_type.upper() == 'BM':\n",
    "        motion = qp.BrownianMotion(sampler, t_final, initial_value, drift, diffusion)\n",
    "        title = f'Realizations of Brownian Motion using {type(sampler).__name__} points'\n",
    "        ylabel = '$W(t)$'\n",
    "    elif motion_type.upper() == 'GBM':\n",
    "        motion = qp.GeometricBrownianMotion(sampler, t_final, initial_value, drift, diffusion)\n",
    "        title = f'Realizations of Geometric Brownian Motion using {type(sampler).__name__} points'\n",
    "        ylabel = '$S(t)$'\n",
    "    else:\n",
    "        raise ValueError(\"motion_type must be 'BM' or 'GBM'\")\n",
    "    \n",
    "    t = motion.gen_samples(n)\n",
    "    initial_values = np.full((n, 1), motion.initial_value)\n",
    "    t_w_init = np.hstack((initial_values, t))\n",
    "    tvec_w_0 = np.hstack(([0], motion.time_vec))\n",
    "\n",
    "    plt.figure(figsize=(7, 4));\n",
    "    _ = plt.plot(tvec_w_0, t_w_init.T); \n",
    "    _ = plt.title(title);\n",
    "    _ = plt.xlabel('$t$');\n",
    "    _ = plt.ylabel(ylabel);\n",
    "    _ = plt.xlim([tvec_w_0[0], tvec_w_0[-1]]);\n",
    "    if png_filename:   # save .png to images/\n",
    "        os.makedirs('images', exist_ok=True)\n",
    "        plt.savefig(f'images/{png_filename}.png', bbox_inches='tight');\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM vs Brownian Motion\n",
    "\n",
    "Paths of the driftless Brownian motion fluctuate symmetrically around the initial value (y = 1) and frequently cross zero into negative territory, while Geometric Brownian Motion paths remain strictly positive throughout their evolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Brownian Motion and Geometric Brownian Motion using the unified plotting function\n",
    "n = 16\n",
    "sampler = qp.Lattice(2**7, seed=42)\n",
    "plot_paths('BM', sampler, t_final=1, initial_value=1, drift=0, diffusion=1, n=n, png_filename='figure_1')\n",
    "plot_paths('GBM', sampler, t_final=1, initial_value=1, drift=0, diffusion=1, n=n, png_filename='figure_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using `plot_gbm_paths`, we generate 32 GBM paths to model stock price, $S(t)$, with initial value $S_0$ = 50, drift coeffient, $\\mu = 0.1$, diffusion coefficient $\\sigma = 0.2$ using IID points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_iid = plot_paths('GBM', qp.IIDStdUniform(2**8, seed=42), t_final=5, initial_value=50, drift=0.1, diffusion=0.2, n=32, png_filename='figure_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM Using Low-Discrepancy Lattice Sequence Distrubtion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same parameter values as in example above, we generate 32 GBM paths to model stock price using low-discrepancy lattice points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_lattice = plot_paths('GBM', qp.Lattice(2**8, seed=42), t_final=5, initial_value=50, drift=0.1, diffusion=0.2, n=32, png_filename='figure_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a more sophisticated visualization function that combines path plotting with statistical analysis by showing both the GBM trajectories and the distribution of final values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_gbm_paths_with_distribution(N, sampler_type, t_final, initial_value, drift, diffusion):\n",
    "    # Create the sampler with dimension = number of time steps for the GBM\n",
    "    # The dimension of the sampler determines the number of time points\n",
    "    n_time_steps = 100  # Fixed number of time steps for visualization\n",
    "    \n",
    "    if sampler_type == 'IIDStdUniform':\n",
    "        sampler = qp.IIDStdUniform(n_time_steps, seed=42)\n",
    "    elif sampler_type == 'Sobol':\n",
    "        sampler = qp.Sobol(n_time_steps, seed=42)\n",
    "    elif sampler_type == 'Lattice':\n",
    "        sampler = qp.Lattice(n_time_steps, seed=42)\n",
    "    elif sampler_type == 'Halton':\n",
    "        sampler = qp.Halton(n_time_steps, seed=42)\n",
    "    else:\n",
    "        sampler = qp.IIDStdUniform(n_time_steps, seed=42)\n",
    "    \n",
    "    gbm = qp.GeometricBrownianMotion(sampler, t_final=t_final, initial_value=initial_value, drift=drift, diffusion=diffusion)\n",
    "    gbm_path = gbm.gen_samples(N)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    T = max(gbm.time_vec)\n",
    "    \n",
    "    # Plot GBM paths (each row is a path, columns are time points)\n",
    "    for i in range(min(N, gbm_path.shape[0])):\n",
    "        _ = ax.plot(gbm.time_vec, gbm_path[i, :], lw=0.75, alpha=0.7, color='skyblue')\n",
    "    \n",
    "    # Set up main plot\n",
    "    _ = ax.set_title(f'Geometric Brownian Motion Paths\\n{N} Simulations, T = {T}, $\\mu$ = {drift:.1f}, $\\sigma$ = {diffusion:.1f}, using {sampler_type} points')\n",
    "    _ = ax.set_xlabel(r'$t$')\n",
    "    _ = ax.set_ylabel(r'$S(t)$')\n",
    "    _ = ax.set_ylim(bottom=0)\n",
    "    _ = ax.set_xlim(0, T)\n",
    "    \n",
    "    # Add histogram\n",
    "    final_values = gbm_path[:, -1]\n",
    "    hist_ax = ax.inset_axes([1.05, 0., 0.5, 1])\n",
    "    _ = hist_ax.hist(final_values, bins=20, density=True, alpha=0.5, color='skyblue', orientation='horizontal')\n",
    "    \n",
    "    # Add theoretical lognormal PDF\n",
    "    shape, _, scale = sc.lognorm.fit(final_values, floc=0)\n",
    "    x = np.linspace(0, max(final_values), 1000)\n",
    "    pdf = sc.lognorm.pdf(x, shape, loc=0, scale=scale)\n",
    "    _ = hist_ax.plot(pdf, x, 'r-', lw=2, label='Lognormal PDF')\n",
    "    \n",
    "    # Finalize histogram\n",
    "    _ = hist_ax.set_title(f'E[$S_T$] = {np.mean(final_values):.4f}', pad=20)\n",
    "    _ = hist_ax.axhline(np.mean(final_values), color='blue', linestyle='--', lw=1.5, label=r'$E[S_T]$')\n",
    "    _ = hist_ax.set_yticks([])\n",
    "    _ = hist_ax.set_xlabel('Density')\n",
    "    _ = hist_ax.legend()\n",
    "    _ = hist_ax.set_ylim(bottom=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization\n",
    "\n",
    "The following code defines a set of sliders to control parameters for simulating paths of GBM. It sets the machine epsilon (eps) as the minimum value for `initial_value`,  `t_final`, and `diffusion`, ensuring they are always positive.  The function `plot_gbm_paths_with_distribution` then visualizes the GBM paths based on the specified parameters in the left subplot and fits a lognormal distribution to the histogram of the data values at the final time point in the right subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.ioff()  # Turn off interactive mode to prevent blank plots\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "slider_style = {'handle_color': 'blue'}\n",
    "\n",
    "@widgets.interact\n",
    "def f(n=widgets.IntSlider(min=0, max=8, step=1, value=7, style=slider_style, description='log₂(N)'),\n",
    "      t_final=widgets.FloatSlider(min=eps, max=10, step=0.1, value=5.0, style=slider_style),\n",
    "      initial_value=widgets.FloatSlider(min=eps, max=100, step=0.1, value=40, style=slider_style),\n",
    "      drift=widgets.FloatSlider(min=-2, max=2, step=0.1, value=0.1, style=slider_style),\n",
    "      diffusion=widgets.FloatSlider(min=eps, max=4, step=0.1, value=0.2, style=slider_style),\n",
    "      sampler=widgets.Dropdown(options=['IIDStdUniform', 'Lattice','Halton','Sobol'], value='IIDStdUniform', description='Sampler')\n",
    "):\n",
    "      plt.close('all')  # Close previous plots \n",
    "      plot_gbm_paths_with_distribution(2**n, sampler, t_final=t_final, initial_value=initial_value, drift=drift, \n",
    "                                    diffusion=diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpu.create_qmcpy_sampler('Lattice', 2, 2**5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuantLib vs QMCPy Comparison\n",
    "\n",
    "In this section, we compare QMCPy's GeometricBrownianMotion implementation with the industry-standard QuantLib library [6] to validate its accuracy and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import QuantLib as ql\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -q QuantLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_theoretical_covariance(S0, mu, sigma, t1, t2):\n",
    "    \"\"\"Compute theoretical covariance matrix for GBM at two time points\"\"\"\n",
    "    return np.array([\n",
    "        [S0**2 * np.exp(2*mu*t1) * (np.exp(sigma**2 * t1) - 1), \n",
    "         S0**2 * np.exp(mu*(t1+t2)) * (np.exp(sigma**2 * t1) - 1)],\n",
    "        [S0**2 * np.exp(mu*(t1+t2)) * (np.exp(sigma**2 * t1) - 1), \n",
    "         S0**2 * np.exp(2*mu*t2) * (np.exp(sigma**2 * t2) - 1)]\n",
    "    ])\n",
    "\n",
    "def calculate_theoretical_statistics(params):\n",
    "    \"\"\"Calculate theoretical mean and std for GBM\"\"\"\n",
    "    theoretical_mean = params['initial_value'] * np.exp(params['mu'] * params['maturity'])\n",
    "    theoretical_std = np.sqrt(params['initial_value']**2 * np.exp(2*params['mu']*params['maturity']) * (np.exp(params['sigma']**2 * params['maturity']) - 1))\n",
    "    return theoretical_mean, theoretical_std\n",
    "\n",
    "def extract_covariance_samples(paths, n_steps, is_quantlib=True):\n",
    "    \"\"\"Extract samples at two time points and compute covariance matrix\"\"\"\n",
    "    if is_quantlib:\n",
    "        idx1, idx2 = int(0.5 * n_steps), n_steps\n",
    "        samples_t1, samples_t2 = paths[:, idx1], paths[:, idx2]\n",
    "    else:  # QMCPy\n",
    "        idx1, idx2 = int(0.5 * (n_steps - 1)), n_steps - 1\n",
    "        samples_t1, samples_t2 = paths[:, idx1], paths[:, idx2]\n",
    "    return np.cov(np.vstack((samples_t1, samples_t2)))\n",
    "\n",
    "#======= Parameters for GBM comparison\n",
    "results_data = []\n",
    "params_ql = {'initial_value': 100, 'mu': 0.05, 'sigma': 0.2, 'maturity': 1.0, 'n_steps': 252, 'n_paths': 2**14}\n",
    "params_qp = {'initial_value': 100, 'mu': 0.05, 'diffusion': 0.2**2, 'maturity': 1.0, 'n_steps': 252, 'n_paths': 2**14}\n",
    "theoretical_mean, theoretical_std = calculate_theoretical_statistics(params_ql)\n",
    "\n",
    "# Add theoretical values once\n",
    "du.add_theoretical_results(results_data, theoretical_mean, theoretical_std)\n",
    "theoretical_cov = compute_theoretical_covariance(params_ql['initial_value'], params_ql['mu'], params_ql['sigma'], 0.5, 1.0)\n",
    "print(\"COMPARISON: QuantLib vs QMCPy GeometricBrownianMotion\")\n",
    "print(\"=\"*55)\n",
    "print(f\"\\nTheoretical covariance matrix:\\n{theoretical_cov}\\n\")\n",
    "print(f\"{'Theoretical':<12} Mean: {theoretical_mean:.2f}, Theoretical Std: {theoretical_std:.2f}\")\n",
    "# Process each sampler\n",
    "for sampler_type in ['IIDStdUniform', 'Sobol', 'Lattice', 'Halton']:\n",
    "    print(f\"\\n\\n{sampler_type = }\")\n",
    "    print(\"~\"*30)\n",
    "    quantlib_paths, qmcpy_paths, ql_gbm, qp_gbm, params_ql, params_qp = du.process_sampler_data(sampler_type, results_data, theoretical_mean, theoretical_std, params_ql, params_qp)\n",
    "\n",
    "    # Compute covariance matrices\n",
    "    if sampler_type in ['IIDStdUniform', 'Sobol']:\n",
    "        quantlib_cov = extract_covariance_samples(quantlib_paths, params_ql['n_steps'], is_quantlib=True)\n",
    "        \n",
    "    qmcpy_cov = extract_covariance_samples(qmcpy_paths, params_qp['n_steps'], is_quantlib=False)\n",
    "\n",
    "    # Final value statistics\n",
    "    if quantlib_paths is not None:\n",
    "        quantlib_final = quantlib_paths[:, -1]\n",
    "    qmcpy_final = qmcpy_paths[:, -1]\n",
    "    theoretical_mean = params_ql['initial_value'] * np.exp(params_ql['mu'] * params_ql['maturity'])\n",
    "    theoretical_std = np.sqrt(params_ql['initial_value']**2 * np.exp(2*params_ql['mu']*params_ql['maturity']) * \n",
    "                            (np.exp(params_ql['sigma']**2 * params_ql['maturity']) - 1))\n",
    "\n",
    "    if quantlib_paths is not None: print(f\"\\nQuantLib sample covariance matrix:\\n{quantlib_cov}\")\n",
    "    print(f\"\\nQMCPy sample covariance matrix:\\n{qmcpy_cov}\")\n",
    "\n",
    "    print(\"\\nFINAL VALUE STATISTICS (t=1 year)\")\n",
    "    print(\"-\"*35)\n",
    "   \n",
    "    for name, final_vals in [(\"QuantLib\", quantlib_final), (\"QMCPy\", qmcpy_final)]:\n",
    "        if name == \"QuantLib\" and quantlib_paths is None:\n",
    "            continue\n",
    "        print(f\"{name:<12} Mean: {np.mean(final_vals):.2f}, Empirical Std:   {np.std(final_vals, ddof=1):.2f}\")\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.round(4)\n",
    "\n",
    "# Store variables for visualization cell (extract individual values from params)\n",
    "paths, qmcpy_paths = quantlib_paths, qmcpy_paths\n",
    "initial_value = params_ql['initial_value']\n",
    "mu = params_ql['mu']\n",
    "sigma = params_ql['sigma']\n",
    "maturity = params_ql['maturity']\n",
    "n_steps = params_ql['n_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization \n",
    "n_plot=50   # Number of paths to plot\n",
    "def plot_paths_on_axis(ax, time_vec, paths_data, title, color, n_plot=50):\n",
    "    \"\"\"Helper function to plot GBM paths on a given axis\"\"\"\n",
    "    if paths_data is not None:\n",
    "        # Work with proper 2D array\n",
    "        paths_data = np.atleast_2d(paths_data)\n",
    "        n_paths_available = paths_data.shape[0]\n",
    "        n_time_points = paths_data.shape[1]\n",
    "        \n",
    "        # Validate dimensions match\n",
    "        if len(time_vec) != n_time_points:\n",
    "            raise ValueError(f\"time_vec length ({len(time_vec)}) must match paths columns ({n_time_points})\")\n",
    "        \n",
    "        for i in range(min(n_plot, n_paths_available)):\n",
    "            ax.plot(time_vec, paths_data[i], alpha=0.2 + 0.3 * (i / n_plot), color=color, linewidth=0.5)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Stock Price')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Create comparison visualization with 2x2 subplots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(11, 8))\n",
    "sampler_type = \"Sobol\"\n",
    "ql_sampler = sampler_type  \n",
    "qp_sampler = sampler_type  \n",
    "\n",
    "# Generate specific data for visualization (ensure we have data for both libraries)\n",
    "params_vis_ql = {'initial_value': 100, 'mu': 0.05, 'sigma': 0.2, 'maturity': 1.0, 'n_steps': 252, 'n_paths': 2**14, 'sampler_type': 'Sobol'}\n",
    "params_vis_qp = {'initial_value': 100, 'mu': 0.05, 'diffusion': 0.2**2, 'maturity': 1.0, 'n_steps': 252, 'n_paths': 2**14, 'sampler_type': 'Sobol'}\n",
    "\n",
    "# Generate paths for visualization\n",
    "vis_quantlib_paths, _ = qlu.generate_quantlib_paths(**params_vis_ql)\n",
    "vis_qmcpy_paths, vis_qp_gbm = qpu.generate_qmcpy_paths(**params_vis_qp)\n",
    "\n",
    "# Print shapes of data\n",
    "print(f\"QuantLib paths shape: {vis_quantlib_paths.shape if vis_quantlib_paths is not None else None}\")\n",
    "print(f\"QMCPy paths shape: {vis_qmcpy_paths.shape if vis_qmcpy_paths is not None else None}\")\n",
    "print(f\"QMCPy paths ndim: {vis_qmcpy_paths.ndim if vis_qmcpy_paths is not None else None}\")\n",
    "\n",
    "# Squeeze any extra dimensions first (handle 3D arrays)\n",
    "if vis_quantlib_paths is not None and vis_quantlib_paths.ndim > 2:\n",
    "    vis_quantlib_paths = np.squeeze(vis_quantlib_paths)\n",
    "    print(f\"Squeezed QuantLib paths to: {vis_quantlib_paths.shape}\")\n",
    "\n",
    "if vis_qmcpy_paths is not None and vis_qmcpy_paths.ndim > 2:\n",
    "    vis_qmcpy_paths = np.squeeze(vis_qmcpy_paths)\n",
    "    print(f\"Squeezed QMCPy paths to: {vis_qmcpy_paths.shape}\")\n",
    "\n",
    "# Ensure paths have shape (n_paths, n_time_steps)\n",
    "# Convention: rows = paths, columns = time steps    \n",
    "# If n_steps (252) is in first dimension and n_paths (16384) in second, transpose\n",
    "if vis_quantlib_paths is not None:\n",
    "    if vis_quantlib_paths.shape[0] == params_vis_ql['n_steps'] or vis_quantlib_paths.shape[0] == params_vis_ql['n_steps'] + 1:\n",
    "        vis_quantlib_paths = vis_quantlib_paths.T\n",
    "        print(f\"Transposed QuantLib paths to: {vis_quantlib_paths.shape}\")\n",
    "\n",
    "if vis_qmcpy_paths is not None:\n",
    "    if vis_qmcpy_paths.shape[0] == params_vis_qp['n_steps'] or vis_qmcpy_paths.shape[0] == params_vis_qp['n_steps'] + 1:\n",
    "        vis_qmcpy_paths = vis_qmcpy_paths.T\n",
    "        print(f\"Transposed QMCPy paths to: {vis_qmcpy_paths.shape}\")\n",
    "\n",
    "# QMCPy paths don't include initial value at t=0, so prepend it to match QuantLib format\n",
    "# This ensures both plots start at the same initial value and time=0\n",
    "if vis_qmcpy_paths is not None:\n",
    "    # Ensure 2D before hstack\n",
    "    vis_qmcpy_paths = np.atleast_2d(vis_qmcpy_paths)\n",
    "    n_qmcpy_paths = vis_qmcpy_paths.shape[0]\n",
    "    initial_col = np.full((n_qmcpy_paths, 1), params_vis_qp['initial_value'])\n",
    "    vis_qmcpy_paths = np.hstack([initial_col, vis_qmcpy_paths])\n",
    "    print(f\"Prepended initial value to QMCPy paths: {vis_qmcpy_paths.shape}\")\n",
    "\n",
    "# Extract final values (last column = final time point)\n",
    "vis_quantlib_final = vis_quantlib_paths[:, -1].flatten() if vis_quantlib_paths is not None else None\n",
    "vis_qmcpy_final = vis_qmcpy_paths[:, -1].flatten() if vis_qmcpy_paths is not None else None\n",
    "\n",
    "print(f\"QuantLib final values shape: {vis_quantlib_final.shape if vis_quantlib_final is not None else None}\")\n",
    "print(f\"QMCPy final values shape: {vis_qmcpy_final.shape if vis_qmcpy_final is not None else None}\")\n",
    "\n",
    "# Get number of samples for titles\n",
    "n_samples = vis_quantlib_paths.shape[0] if vis_quantlib_paths is not None else vis_qmcpy_paths.shape[0]\n",
    "\n",
    "# Create time grids that match the actual data dimensions\n",
    "# Both now start at t=0 and end at maturity\n",
    "time_grid_ql = np.linspace(0, maturity, vis_quantlib_paths.shape[1])\n",
    "time_grid_qp = np.linspace(0, maturity, vis_qmcpy_paths.shape[1])\n",
    "\n",
    "plot_data = [ (ax1, time_grid_ql, vis_quantlib_paths, f'QuantLib ({ql_sampler}) GBM Paths ({n_plot} from {n_samples})', 'blue'),\n",
    "              (ax2, time_grid_qp, vis_qmcpy_paths, f'QMCPy ({qp_sampler}) GBM Paths ({n_plot} from {n_samples})', 'red') ]\n",
    "for ax, time_grid, data, title, color in plot_data:\n",
    "    plot_paths_on_axis(ax, time_grid, data, title, color)\n",
    "\n",
    "# Final value distributions\n",
    "for final_vals, color, label, sampler in [(vis_quantlib_final, 'blue', 'QuantLib', ql_sampler), (vis_qmcpy_final, 'red', 'QMCPy', qp_sampler)]:\n",
    "    if final_vals is not None:\n",
    "        ax3.hist(final_vals, bins=50, alpha=0.6, color=color, label=f'{label} ({sampler})', density=True)\n",
    "ax3.set_title(f'Final Value Distributions (t=1)', fontsize=11, fontweight='bold')\n",
    "ax3.set_xlabel('Stock Price')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# QMCPy covariance matrix heatmap\n",
    "im = ax4.imshow(vis_qp_gbm.covariance_gbm, cmap='viridis', aspect='equal') # origin='lower'\n",
    "ax4.set_title(f'QMCPy ({qp_sampler}) Covariance Matrix Heatmap', fontsize=11, fontweight='bold')\n",
    "ax4.set_xlabel('Time')\n",
    "ax4.set_ylabel('Time')\n",
    "\n",
    "# Set custom tick labels using time_vec\n",
    "time_ticks = np.arange(0, len(vis_qp_gbm.time_vec), max(1, len(vis_qp_gbm.time_vec)//5))  # Show ~5 ticks\n",
    "ax4.set_xticks(time_ticks)\n",
    "ax4.set_yticks(time_ticks)\n",
    "ax4.set_xticklabels([f'{vis_qp_gbm.time_vec[i]:.1f}' for i in time_ticks])\n",
    "ax4.set_yticklabels([f'{vis_qp_gbm.time_vec[i]:.1f}' for i in time_ticks])\n",
    "cbar = plt.colorbar(im, ax=ax4, shrink=0.8)   # Add colorbar\n",
    "cbar.set_label('Covariance Value', rotation=270, labelpad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/figure_5.png', bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For benchmarking, we can use IPython's built-in `%timeit` magic command which automatically handles warm-up, multiple runs, and statistical analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_quantlib_samplers(samplers_to_test, base_params):\n",
    "    \"\"\"Benchmark QuantLib with different samplers\"\"\"\n",
    "    timing_results = {}\n",
    "    for sampler_type in samplers_to_test:\n",
    "        print(f\"QuantLib ({sampler_type}) timing:\")\n",
    "        benchmark_func = lambda st=sampler_type: qlu.generate_quantlib_paths(**base_params, sampler_type=st)\n",
    "        timing_result = %timeit -n 10 -r 1 -o benchmark_func()\n",
    "        timing_results[sampler_type] = {\n",
    "            'average': timing_result.average,\n",
    "            'stdev': timing_result.stdev,\n",
    "            'loops': timing_result.loops,\n",
    "            'repeat': timing_result.repeat\n",
    "        }\n",
    "    return timing_results\n",
    "\n",
    "def benchmark_qmcpy_samplers(samplers_to_test, base_params):\n",
    "    \"\"\"Benchmark QMCPy samplers with timing measurements\"\"\"\n",
    "    timing_results = {}\n",
    "    \n",
    "    # Convert QuantLib parameters to QMCPy parameters if needed\n",
    "    qp_params = base_params.copy()\n",
    "    if 'sigma' in qp_params:\n",
    "        qp_params['diffusion'] = qp_params.pop('sigma') ** 2  # Convert sigma to diffusion (sigma²)\n",
    "    \n",
    "    for sampler_type in samplers_to_test:\n",
    "        print(f\"QMCPy ({sampler_type}) timing:\")\n",
    "        benchmark_func = lambda st=sampler_type: qpu.generate_qmcpy_paths(**qp_params, sampler_type=st)\n",
    "        timing_result = %timeit -n 10 -r 1 -o benchmark_func()\n",
    "        timing_results[sampler_type] = {\n",
    "            'average': timing_result.average,\n",
    "            'stdev': timing_result.stdev,\n",
    "            'loops': timing_result.loops,\n",
    "            'repeat': timing_result.repeat\n",
    "        }\n",
    "    return timing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark QuantLib and QMCPy with different samplers\n",
    "quantlib_samplers_to_benchmark = ['IIDStdUniform', 'Sobol']\n",
    "qmcpy_samplers_to_benchmark = ['IIDStdUniform', 'Sobol', 'Lattice', 'Halton']\n",
    "# Create base params without sampler_type to avoid conflicts  \n",
    "base_ql_params = {k: v for k, v in params_ql.items() if k != 'sampler_type'}\n",
    "# Add the required parameters for QMCPy benchmarking\n",
    "base_ql_params.update({'n_steps': 252, 'n_paths': 2**14})\n",
    "# Create QMCPy parameters (note: diffusion instead of sigma)\n",
    "base_qp_params = {\n",
    "    'initial_value': 100, \n",
    "    'mu': 0.05, \n",
    "    'diffusion': 0.2**2,  # sigma^2 for QMCPy\n",
    "    'maturity': 1.0, \n",
    "    'n_steps': 252, \n",
    "    'n_paths': 2**14\n",
    "}\n",
    "# Run benchmarks\n",
    "quantlib_timing_results = benchmark_quantlib_samplers(quantlib_samplers_to_benchmark, base_ql_params)\n",
    "qmcpy_timing_results = benchmark_qmcpy_samplers(qmcpy_samplers_to_benchmark, base_qp_params)\n",
    "# Create comprehensive timing table\n",
    "timing_df = du.create_timing_dataframe(quantlib_timing_results, qmcpy_timing_results, quantlib_samplers_to_benchmark[0])\n",
    "timing_df.round(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output results to LaTeX\n",
    "results_df = pd.merge(results_df, timing_df, on=['Method', 'Sampler'])\n",
    "# Format the results dataframe\n",
    "numeric_cols = ['Mean', 'Std Dev', 'Mean Absolute Error', 'Std Dev Error', 'Mean Time (s)', 'Std Dev (s)', 'Speedup']\n",
    "results_formatted = lu.format_results_dataframe(results_df, numeric_cols)\n",
    "# Generate and save LaTeX table\n",
    "title =  \"GBM Final Value Statistics and Performance Comparison\"\n",
    "latex_table = lu.generate_latex_table(results_formatted, title, \"tab2\")\n",
    "with open('outputs/gbm_comparison_table.tex', 'w') as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plot using sample data (2 subplots)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "# Extract data for plotting\n",
    "samplers, qmcpy_errors, qmcpy_times, quantlib_errors, quantlib_times, theoretical_mean = du.extract_comparison_data(results_df)\n",
    "# Create subplots \n",
    "pu.plot_error_comparison(ax1, samplers, qmcpy_errors, quantlib_errors)\n",
    "pu.plot_performance_comparison(ax2, samplers, qmcpy_times, quantlib_times)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/figure_6.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# ========================================\n",
    "# MAIN EXPERIMENT RUNNER\n",
    "# ========================================\n",
    "def run_single_configuration(series_name, n_steps, n_paths):\n",
    "    \"\"\"Run benchmarking for a single parameter configuration\"\"\"\n",
    "    print(f\"\\nTesting n_steps = {n_steps}, n_paths = {n_paths}\")\n",
    "    \n",
    "    # Calculate theoretical values\n",
    "    gbm_params = cf.get_gbm_parameters()\n",
    "    theoretical_mean, theoretical_std = calculate_theoretical_statistics(gbm_params)\n",
    "    \n",
    "    # Prepare benchmark parameters for QuantLib (with sigma)\n",
    "    ql_params = {**gbm_params, 'n_steps': n_steps, 'n_paths': n_paths}\n",
    "    \n",
    "    # Prepare benchmark parameters for QMCPy (with diffusion instead of sigma)\n",
    "    qp_params = {\n",
    "        'initial_value': gbm_params['initial_value'],\n",
    "        'mu': gbm_params['mu'],\n",
    "        'diffusion': gbm_params['sigma']**2,  # Convert sigma to diffusion\n",
    "        'maturity': gbm_params['maturity'],\n",
    "        'n_steps': n_steps,\n",
    "        'n_paths': n_paths\n",
    "    }\n",
    "    \n",
    "    # Run benchmarks\n",
    "    samplers = cf.get_sampler_configurations()\n",
    "    print(\"  Benchmarking QuantLib...\")\n",
    "    ql_timing = benchmark_quantlib_samplers(samplers['quantlib_samplers'], ql_params)\n",
    "    \n",
    "    print(\"  Benchmarking QMCPy...\")\n",
    "    qp_timing = benchmark_qmcpy_samplers(samplers['all_samplers'], qp_params)\n",
    "    \n",
    "    # Collect results for all samplers\n",
    "    results = []\n",
    "    du.add_theoretical_row(results, series_name, n_steps, n_paths, theoretical_mean, theoretical_std)\n",
    "    \n",
    "    for sampler in samplers['all_samplers']:\n",
    "        print(f\"    Processing {sampler}...\")\n",
    "        sampler_results = du.collect_library_results(\n",
    "            sampler, series_name, n_steps, n_paths,\n",
    "            ql_timing, qp_timing, theoretical_mean, theoretical_std\n",
    "        )\n",
    "        results.extend(sampler_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_time_steps_series():\n",
    "    \"\"\"Run experiments varying time steps with fixed paths\"\"\"\n",
    "    config = cf.get_experiment_configurations()['time_steps']\n",
    "    print(f\"\\nSERIES 1: Varying Time Steps (n_paths fixed at {config['fixed_paths']})\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    all_results = []\n",
    "    for n_steps in config['range']:\n",
    "        results = run_single_configuration(\n",
    "            config['series_name'], n_steps, config['fixed_paths']\n",
    "        )\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def run_paths_series():\n",
    "    \"\"\"Run experiments varying paths with fixed time steps\"\"\"\n",
    "    config = cf.get_experiment_configurations()['paths']\n",
    "    print(f\"\\nSERIES 2: Varying Number of Paths (n_steps fixed at {config['fixed_steps']})\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    all_results = []\n",
    "    for n_paths in config['range']:\n",
    "        results = run_single_configuration(\n",
    "            config['series_name'], config['fixed_steps'], n_paths\n",
    "        )\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def run_comprehensive_parameter_sweep():\n",
    "    \"\"\"\n",
    "    Run comprehensive parameter sweep experiments:\n",
    "    1. Vary time steps with fixed paths\n",
    "    2. Vary paths with fixed time steps\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    all_results.extend(run_time_steps_series())\n",
    "    all_results.extend(run_paths_series())\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# ========================================\n",
    "# MAIN EXECUTION\n",
    "# ========================================\n",
    "\n",
    "# Run the comprehensive parameter sweep\n",
    "sweep_results_df = run_comprehensive_parameter_sweep()\n",
    "# Create visualizations\n",
    "pu.create_parameter_sweep_plots(sweep_results_df)\n",
    "\n",
    "# Display sample of results\n",
    "print(\"\\nSample of results:\")\n",
    "sample_results = sweep_results_df[sweep_results_df['Method'] != 'Theoretical'].head(10)\n",
    "print(sample_results[['Series', 'n_steps', 'n_paths', 'Method', 'Sampler', 'Runtime (s)', 'Mean Absolute Error']].round(10))\n",
    "\n",
    "# Save results for later analysis\n",
    "sweep_results_df.to_csv('outputs/parameter_sweep_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/figure_7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import averaged_mae as am\n",
    "cf.is_debug = True\n",
    "am.plot_mae_vs_paths(replications = 3)s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QMCPy vs QuantLib:** Both libraries produce statistically equivalent GBM simulations that match theoretical values. QMCPy typically runs 1.5 to 2 times faster due to vectorized operations, lazy loading, and optimized memory management. More importantly, it demonstrates superior numerical accuracy (lower mean absolute errors) with Sobol, lattice and Halton samplers, making it excellent for research and high-performance applications. QuantLib remains the industry standard for production systems requiring comprehensive derivatives support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need different samplers, create efficiently\n",
    "base_params = {'t_final': 1, 'initial_value': 100, 'drift': 0.05, 'diffusion': 0.2}\n",
    "\n",
    "sobol_gbm = qp.GeometricBrownianMotion(qp.Sobol(252), **base_params)\n",
    "lattice_gbm = qp.GeometricBrownianMotion(qp.Lattice(252), **base_params)\n",
    "halton_gbm = qp.GeometricBrownianMotion(qp.Halton(252), **base_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "The authors thank Joshua Jay Herman and Jiangrui Kang for their insightful feedback and help with the blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* $[1]$ Glasserman, P. (2003). *Monte Carlo Methods in Financial Engineering*. Springer.\n",
    "* $[2]$ Choi, S.-C. T., Hickernell, F. J., Jagadeeswaran, R., McCourt, M. J., and Sorokin, A. G. (2022). Quasi-Monte Carlo Software. In Alexander Keller, editor, *Monte Carlo and Quasi-Monte Carlo Methods*. Springer International Publishing.\n",
    "* $[3]$ Choi, S.-C. T., Hickernell, F. J., Jagadeeswaran, R., McCourt, M., and Sorokin, A. (2020--2025). QMCPy: A quasi-Monte Carlo Python Library, Version 2.1. https://qmcpy.readthedocs.io/.\n",
    "* $[4]$ Hull, J. C. (2017). *Options, Futures, and Other Derivatives*. Pearson, 10th edition.\n",
    "* $[5]$ Ross, S. M. (2014). *Introduction to Probability Models*. Academic Press, 11th edition.\n",
    "* $[6]$ The QuantLib contributors (2003--2025). QuantLib: A free/open-source library for quantitative finance, Version 1.38. https://www.quantlib.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Covariance Matrix Derivation for Geometric Brownian Motion\n",
    "\n",
    "Here we derive the covariance matrix of $(S(t_1), \\ldots , S(t_n))$ for one-dimensional Geometric Brownian Motion defined as $S(t) = S_0 \\, e^{\\big(\\mu - \\frac{\\sigma^2}{2}\\big)  t + \\sigma W(t)}$, where $W(t)$ is a standard one-dimensional Brownian motion.\n",
    "\n",
    "\n",
    "1.  **Recall the definition of covariance:**\n",
    "    $$\\text{Cov}(S(t_i), S(t_j)) = E[S(t_i)S(t_j)] - E[S(t_i)]E[S(t_j)].$$\n",
    "\n",
    "2.  **Calculate the product of expectations:**\n",
    "    The expected value of $S(t)$ is $E[S(t)] = S_0 e^{\\mu t}$.\n",
    "    Therefore, the product of the expectations is:\n",
    "    $$E[S(t_i)]E[S(t_j)] = (S_0 e^{\\mu t_i})(S_0 e^{\\mu t_j}) = S_0^2 e^{\\mu(t_i + t_j)}$$\n",
    "\n",
    "3.  **Calculate the expectation of the product, $E[S(t_i)S(t_j)]$:**\n",
    "    $$\\begin{aligned}\n",
    "    S(t_i)S(t_j) &= S_0 e^{(\\mu - \\frac{\\sigma^2}{2})t_i + \\sigma W(t_i)} \\cdot S_0 e^{(\\mu - \\frac{\\sigma^2}{2})t_j + \\sigma W(t_j)} \\\\\n",
    "    &= S_0^2 \\exp\\left( (\\mu - \\frac{\\sigma^2}{2})(t_i + t_j) + \\sigma \\left(W(t_i) + W(t_j) \\right) \\right)\n",
    "    \\end{aligned}$$\n",
    "    The exponent is a normal random variable. Let's call it $Y$:\n",
    "    $$Y = (\\mu - \\frac{\\sigma^2}{2})(t_i + t_j) + \\sigma\\left(W(t_i) + W(t_j)\\right)$$\n",
    "    To find the expectation of $e^Y$, we use the property that if $Y \\sim N(\\text{mean}, \\text{variance})$, then $E[e^Y] = e^{\\text{mean} + \\frac{1}{2}\\text{variance}}$.\n",
    "\n",
    "    * The mean of $Y$ is\n",
    "        $E[Y] = E[(\\mu - \\frac{\\sigma^2}{2})(t_i + t_j) + \\sigma(W(t_i) + W(t_j))] = (\\mu - \\frac{\\sigma^2}{2})(t_i + t_j).$\n",
    "\n",
    "    * The variance of $Y$ is\n",
    "        $$\\begin{aligned}\n",
    "        \\text{Var}(Y) &= \\text{Var}[(\\mu - \\frac{\\sigma^2}{2})(t_i + t_j) + \\sigma(W(t_i) + W(t_j))] \\\\\n",
    "        &= \\text{Var}[\\sigma(W(t_i) + W(t_j))] \\\\\n",
    "        &= \\sigma^2 \\text{Var}(W(t_i) + W(t_j)) \\\\\n",
    "        &= \\sigma^2(\\text{Var}(W(t_i)) + \\text{Var}(W(t_j)) + 2\\text{Cov}(W(t_i), W(t_j))) \\\\\n",
    "        &= \\sigma^2(t_i + t_j + 2\\min(t_i, t_j))\n",
    "         \\end{aligned}$$\n",
    "    Now we can compute $E[S(t_i)S(t_j)] = S_0^2 E[e^Y]$:\n",
    "    $$\\begin{aligned}\n",
    "    E[S(t_i)S(t_j)] &= S_0^2 \\exp\\left( E[Y] + \\frac{1}{2}\\text{Var}(Y) \\right) \\\\\n",
    "    &= S_0^2 \\exp\\left( (\\mu - \\frac{\\sigma^2}{2})(t_i + t_j) + \\frac{1}{2}\\sigma^2 \\left(t_i + t_j + 2\\min(t_i, t_j)\\right) \\right)\n",
    "    \\end{aligned}$$\n",
    "    Simplifying the exponent:\n",
    "    $$\\begin{aligned}\n",
    "    &\\mu(t_i + t_j) - \\frac{\\sigma^2}{2}(t_i+t_j) + \\frac{\\sigma^2}{2}(t_i+t_j) + \\sigma^2\\min(t_i,t_j) \\\\\n",
    "    &= \\mu(t_i + t_j) + \\sigma^2\\min(t_i,t_j)\n",
    "    \\end{aligned}$$\n",
    "    So, the final expression for the expectation of the product is:\n",
    "    $$E[S(t_i)S(t_j)] = S_0^2 e^{\\mu(t_i + t_j) + \\sigma^2\\min(t_i, t_j)}$$\n",
    "\n",
    "4.  **Combine the terms to get the covariance:**\n",
    "    $$\\begin{aligned}\n",
    "    \\text{Cov}(S(t_i), S(t_j)) &= S_0^2 e^{\\mu(t_i + t_j) + \\sigma^2\\min(t_i, t_j)} - S_0^2 e^{\\mu(t_i + t_j)} \\\\\n",
    "    &= S_0^2 e^{\\mu(t_i + t_j)} \\left(e^{\\sigma^2 \\min(t_i, t_j)} - 1\\right).\n",
    "    \\end{aligned}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qmcpy",
   "language": "python",
   "name": "qmcpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
