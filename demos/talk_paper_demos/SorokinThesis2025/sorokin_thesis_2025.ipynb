{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aleksei Sorokin PhD Thesis 2025: Quasi-Monte Carlo Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qmcpy as qp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.4 ms, sys: 32.7 ms, total: 81.2 ms\n",
      "Wall time: 92.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "lattice = qp.Lattice(\n",
    "    dimension = 52,\n",
    "    randomize = \"shift\", # for unrandomized lattice set randomize = None\n",
    "    replications = 16, # R\n",
    "    order = \"radical inverse\", # also supports \"linear\"\n",
    "    seed = None, # pass integer seed for reproducibility\n",
    "    generating_vector = \"mps.exod2_base2_m20_CKN.txt\")\n",
    "x = lattice(2**16) # a numpy.ndarray with shape 16 x 65536 x 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 362 ms, sys: 113 ms, total: 475 ms\n",
      "Wall time: 484 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dnb2 = qp.DigitalNetB2(\n",
    "    dimension = 52, \n",
    "    randomize = \"LMS DS\", # Matousek's LMS then a digital shift\n",
    "    # other options [\"NUS\", \"DS\", \"LMS\", None]\n",
    "    t = 64, # number of LMS bits i.e. number of rows in S_j\n",
    "    alpha = 2, # interlacing factor for higher order digital nets\n",
    "    replications = 16, # R\n",
    "    order = \"radical inverse\", # also supports \"Gray code\"\n",
    "    seed = None, # pass integer seed for reproducibility\n",
    "    generating_matrices = \"joe_kuo.6.21201.txt\")\n",
    "x = dnb2(2**16) # a numpy.ndarray with shape 16 x 65536 x 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 320 ms, sys: 58.6 ms, total: 378 ms\n",
      "Wall time: 379 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "halton = qp.Halton(\n",
    "    dimension = 52, \n",
    "    randomize = \"LMS DP\", # Matousek's LMS then a digital permutation\n",
    "    # other options [\"LMS DS\", \"LMS\", \"DP\", \"DS\", \"NUS\", \"QRNG\", None]\n",
    "    t = 64, # number of LMS digits i.e. number of rows in S_j\n",
    "    replications = 16, # R\n",
    "    seed = None) # pass integer seed for reproducibility\n",
    "x = halton(2**10) # a numpy.ndarray with shape 16 x 1024 x 52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lattice + FFTBR + IFFTBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3 # dimension \n",
    "m = 10 # will generate 2^m points\n",
    "n = 2**m # number of points\n",
    "lattice = qp.Lattice(d) # default to radical inverse order\n",
    "kernel = qp.KernelShiftInvar(\n",
    "    d, # dimension \n",
    "    alpha = [1,2,3], # per dimension smoothness parameters\n",
    "    lengthscales = [1, 1/2, 1/4]) # per dimension product weights\n",
    "x = lattice(n_min=0,n_max=n) # shape=(n,d) lattice points\n",
    "y = np.random.rand(n) # shape=(n,) random uniforms\n",
    "# fast matrix multiplication and linear system solve\n",
    "k1 = kernel(x,x[0]) # shape=(n,) first column of Gram matrix\n",
    "lam = np.sqrt(n)*qp.fftbr(k1) # vector of eigenvalues\n",
    "yt = qp.fftbr(y)\n",
    "u = qp.ifftbr(yt*lam) # fast matrix multiplication \n",
    "v = qp.ifftbr(yt/lam) # fast linear system solve\n",
    "# efficient fast transform updates\n",
    "ynew = np.random.rand(n) # shape=(n,) new random uniforms\n",
    "omega = qp.omega_fftbr(m) # shape=(n,)\n",
    "ytnew = qp.fftbr(ynew) # shape=(n,)\n",
    "ytfull = np.concatenate([yt+omega*ytnew,yt-omega*ytnew])/np.sqrt(2) # shape=(2n,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow matrix multiplication and linear system solve\n",
    "kmat = kernel(x[:,None,:],x[None,:,:]) # shape=(n,n)\n",
    "u_slow = kmat@y # matrix multiplication\n",
    "v_slow = np.linalg.solve(kmat,y) # solve a linear system\n",
    "# verify correctness\n",
    "assert np.allclose(u,u_slow)\n",
    "assert np.allclose(v,v_slow)\n",
    "# get next samples \n",
    "xnew = lattice(n_min=n,n_max=2*n) # shape=(n,d) new lattice points\n",
    "k1new = kernel(xnew,x[0]) # shape=(n,) new values in the first column\n",
    "# inefficient fast transform update \n",
    "k1full = np.concatenate([k1,k1new]) # shape=(2*n,) full first column\n",
    "lamfull_inefficient = np.sqrt(2*n)*qp.fftbr(k1full) # shape=(2*n,) full eigenvalues\n",
    "yfull = np.concatenate([y,ynew]) # shape=(2*n,) full random values\n",
    "ytfull_inefficient = qp.fftbr(yfull) # shape=(2*n,) full transformed points\n",
    "# efficient fast transform updates\n",
    "lamnew = np.sqrt(n)*qp.fftbr(k1new) # shape=(n,) new eigenvalues\n",
    "lamfull = np.hstack([lam+omega*lamnew,lam-omega*lamnew])\n",
    "# verify correctness\n",
    "assert np.allclose(lamfull,lamfull_inefficient)\n",
    "assert np.allclose(ytfull,ytfull_inefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital Net + FWHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3 # dimension \n",
    "m = 10 # will generate 2^m points\n",
    "n = 2**m # number of points\n",
    "dnb2 = qp.DigitalNetB2(d) # default to radical inverse order\n",
    "kernel = qp.KernelDigShiftInvar(\n",
    "    d, # dimension \n",
    "    t = dnb2.t, # number of bits in integer representation of points\n",
    "    alpha = [1,2,3], # per dimension smoothness parameters\n",
    "    lengthscales = [1, 1/2, 1/4]) # per dimension product weights\n",
    "x = dnb2(n_min=0,n_max=n) # shape=(n,d) digital net\n",
    "y = np.random.rand(n) # shape=(n,) random uniforms\n",
    "# fast matrix multiplication and linear system solve\n",
    "k1 = kernel(x,x[0]) # shape=(n,) first column of Gram matrix\n",
    "lam = np.sqrt(n)*qp.fwht(k1) # vector of eigenvalues\n",
    "yt = qp.fwht(y)\n",
    "u = qp.fwht(yt*lam) # fast matrix multiplication \n",
    "v = qp.fwht(yt/lam) # fast linear system solve\n",
    "# efficient fast transform updates\n",
    "ynew = np.random.rand(n) # shape=(n,) new random uniforms\n",
    "omega = qp.omega_fwht(m) # shape=(n,)\n",
    "ytnew = qp.fwht(ynew) # shape=(n,)\n",
    "ytfull = np.concatenate([yt+omega*ytnew,yt-omega*ytnew])/np.sqrt(2) # shape=(2n,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow matrix multiplication and linear system solve\n",
    "kmat = kernel(x[:,None,:],x[None,:,:]) # shape=(n,n)\n",
    "u_slow = kmat@y # matrix multiplication\n",
    "v_slow = np.linalg.solve(kmat,y) # solve a linear system\n",
    "# verify correctness\n",
    "assert np.allclose(u,u_slow)\n",
    "assert np.allclose(v,v_slow)\n",
    "# get next samples \n",
    "xnew = dnb2(n_min=n,n_max=2*n) # shape=(n,d) new digital net points\n",
    "k1new = kernel(xnew,x[0]) # shape=(n,) new values in the first column\n",
    "# inefficient fast transform update \n",
    "k1full = np.concatenate([k1,k1new]) # shape=(2*n,) full first column\n",
    "lamfull_inefficient = np.sqrt(2*n)*qp.fwht(k1full) # shape=(2*n,) full eigenvalues\n",
    "yfull = np.concatenate([y,ynew]) # shape=(2*n,) full random values\n",
    "ytfull_inefficient = qp.fwht(yfull) # shape=(2*n,) full transformed points\n",
    "# efficient fast transform updates\n",
    "lamnew = np.sqrt(n)*qp.fwht(k1new) # shape=(n,) new eigenvalues\n",
    "lamfull = np.hstack([lam+omega*lamnew,lam-omega*lamnew])\n",
    "# verify correctness\n",
    "assert np.allclose(lamfull,lamfull_inefficient)\n",
    "assert np.allclose(ytfull,ytfull_inefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014936813948394042\n",
      "5.247445301861484e-07\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "def gen_corner_peak_2(x):\n",
    "    d = x.shape[-1] # x.shape=(...,n,d), e.g., (n,d) or (R,n,d) \n",
    "    c_tilde = 1/np.arange(1,d+1)**2\n",
    "    c = 0.25*c_tilde/np.sum(c_tilde)\n",
    "    y = (1+np.sum(c*x,axis=-1))**(-(d+1)) \n",
    "    return y # y.shape=(...,n), e.g., (n,) or (R,n)\n",
    "R = 10 # number of randomizations\n",
    "n = 2**15 # number of points \n",
    "d = 50 # dimension\n",
    "dnb2 = qp.DigitalNet(dimension=d, replications=R, seed=7, alpha=3)\n",
    "x = dnb2(n) # x.shape=(R,n,d)\n",
    "y = gen_corner_peak_2(x) # y.shape=(R,n) \n",
    "muhats = np.mean(y,axis=1) # muhats.shape=(R,)\n",
    "muhat_aggregate = np.mean(muhats) # muhat_aggregate is a scalar \n",
    "print(muhat_aggregate)\n",
    "\"\"\" 0.014936813948394042 \"\"\"\n",
    "alpha = 0.01 # uncertainty level\n",
    "t_star = -scipy.stats.t.ppf(alpha/2,df=R-1) # quantile of Student's t \n",
    "stdhat = np.std(muhats,ddof=1) # unbiased estimate of standard deviation\n",
    "std_error = t_star*stdhat/np.sqrt(R)\n",
    "print(std_error)\n",
    "\"\"\" 5.247445301861484e-07 \"\"\"\n",
    "conf_int = [muhat_aggregate-std_error,muhat_aggregate+std_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014950908095474802\n",
      "2.7968149935497788e-05\n",
      "Data (Data)\n",
      "    solution        0.015\n",
      "    comb_bound_low  0.015\n",
      "    comb_bound_high 0.015\n",
      "    comb_bound_diff 5.59e-05\n",
      "    comb_flags      1\n",
      "    n_total         10240\n",
      "    n               10240\n",
      "    n_rep           2^(10)\n",
      "    time_integrate  0.005\n",
      "CubQMCRepStudentT (AbstractStoppingCriterion)\n",
      "    inflate         1\n",
      "    alpha           0.010\n",
      "    abs_tol         1.00e-04\n",
      "    rel_tol         0\n",
      "    n_init          2^(8)\n",
      "    n_limit         2^(30)\n",
      "CustomFun (AbstractIntegrand)\n",
      "Uniform (AbstractTrueMeasure)\n",
      "    lower_bound     0\n",
      "    upper_bound     1\n",
      "DigitalNetB2 (AbstractLDDiscreteDistribution)\n",
      "    d               50\n",
      "    replications    10\n",
      "    randomize       LMS DS\n",
      "    gen_mats_source joe_kuo.6.21201.txt\n",
      "    order           RADICAL INVERSE\n",
      "    t               63\n",
      "    alpha           3\n",
      "    n_limit         2^(32)\n",
      "    entropy         7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nData (Data)\\n    solution        0.015\\n    comb_bound_low  0.015\\n    comb_bound_high 0.015\\n    comb_bound_diff 5.59e-05\\n    comb_flags      1\\n    n_total         10240\\n    n               10240\\n    n_rep           2^(10)\\n    time_integrate  0.019\\nCubQMCRepStudentT (AbstractStoppingCriterion)\\n    inflate         1\\n    alpha           0.010\\n    abs_tol         1.00e-04\\n    rel_tol         0\\n    n_init          2^(8)\\n    n_limit         2^(30)\\nCustomFun (AbstractIntegrand)\\nUniform (AbstractTrueMeasure)\\n    lower_bound     0\\n    upper_bound     1\\nDigitalNetB2 (AbstractLDDiscreteDistribution)\\n    d               50\\n    replications    10\\n    randomize       LMS DS\\n    gen_mats_source joe_kuo.6.21201.txt\\n    order           RADICAL INVERSE\\n    t               63\\n    alpha           3\\n    n_limit         2^(32)\\n    entropy         7\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_corner_peak_2(x):\n",
    "    d = x.shape[-1] # x.shape=(...,n,d), e.g., (n,d) or (R,n,d) \n",
    "    c_tilde = 1/np.arange(1,d+1)**2\n",
    "    c = 0.25*c_tilde/np.sum(c_tilde)\n",
    "    y = (1+np.sum(c*x,axis=-1))**(-(d+1)) \n",
    "    return y # y.shape=(...,n), e.g., (n,) or (R,n)\n",
    "R = 10\n",
    "d = 50 \n",
    "dnb2 = qp.DigitalNet(dimension=d, replications=R, seed=7, alpha=3)\n",
    "true_measure = qp.Uniform(dnb2, lower_bound=0, upper_bound=1)\n",
    "integrand = qp.CustomFun(true_measure=true_measure, g=gen_corner_peak_2)\n",
    "# equivalent to \n",
    "# integrand = qp.Genz(dnb2, kind_func=\"CORNER PEAK\", kind_coeff=2)\n",
    "qmc_algo = qp.CubQMCRepStudentT(integrand, abs_tol=1e-4)\n",
    "solution,data = qmc_algo.integrate() # run adaptive QMC algorithm \n",
    "print(solution)\n",
    "\"\"\" 0.014950908095474802 \"\"\"\n",
    "conf_int = [data.comb_bound_low,data.comb_bound_high]\n",
    "std_error = (conf_int[1]-conf_int[0])/2\n",
    "print(std_error)\n",
    "\"\"\" 2.7968149935497788e-05 \"\"\"\n",
    "print(data)\n",
    "\"\"\"\n",
    "Data (Data)\n",
    "    solution        0.015\n",
    "    comb_bound_low  0.015\n",
    "    comb_bound_high 0.015\n",
    "    comb_bound_diff 5.59e-05\n",
    "    comb_flags      1\n",
    "    n_total         10240\n",
    "    n               10240\n",
    "    n_rep           2^(10)\n",
    "    time_integrate  0.019\n",
    "CubQMCRepStudentT (AbstractStoppingCriterion)\n",
    "    inflate         1\n",
    "    alpha           0.010\n",
    "    abs_tol         1.00e-04\n",
    "    rel_tol         0\n",
    "    n_init          2^(8)\n",
    "    n_limit         2^(30)\n",
    "CustomFun (AbstractIntegrand)\n",
    "Uniform (AbstractTrueMeasure)\n",
    "    lower_bound     0\n",
    "    upper_bound     1\n",
    "DigitalNetB2 (AbstractLDDiscreteDistribution)\n",
    "    d               50\n",
    "    replications    10\n",
    "    randomize       LMS DS\n",
    "    gen_mats_source joe_kuo.6.21201.txt\n",
    "    order           RADICAL INVERSE\n",
    "    t               63\n",
    "    alpha           3\n",
    "    n_limit         2^(32)\n",
    "    entropy         7\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantilever Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data (Data)\n",
      "    solution        [2.426e+00 3.750e+04]\n",
      "    comb_bound_low  [2.425e+00 3.750e+04]\n",
      "    comb_bound_high [2.427e+00 3.750e+04]\n",
      "    comb_bound_diff [0.002 0.041]\n",
      "    comb_flags      [ True  True]\n",
      "    n_total         2^(18)\n",
      "    n               [  1024 262144]\n",
      "    time_integrate  0.061\n",
      "CubQMCNetG (AbstractStoppingCriterion)\n",
      "    abs_tol         0.001\n",
      "    rel_tol         1.00e-06\n",
      "    n_init          2^(10)\n",
      "    n_limit         2^(35)\n",
      "CustomFun (AbstractIntegrand)\n",
      "Gaussian (AbstractTrueMeasure)\n",
      "    mean            [2.9e+07 5.0e+02 1.0e+03]\n",
      "    covariance      [[2.102e+12 0.000e+00 0.000e+00]\n",
      "                     [0.000e+00 1.000e+04 0.000e+00]\n",
      "                     [0.000e+00 0.000e+00 1.000e+04]]\n",
      "    decomp_type     PCA\n",
      "DigitalNetB2 (AbstractLDDiscreteDistribution)\n",
      "    d               3\n",
      "    replications    1\n",
      "    randomize       LMS DS\n",
      "    gen_mats_source joe_kuo.6.21201.txt\n",
      "    order           RADICAL INVERSE\n",
      "    t               63\n",
      "    alpha           1\n",
      "    n_limit         2^(32)\n",
      "    entropy         7\n"
     ]
    }
   ],
   "source": [
    "def cantilever_beam_function(T,compute_flags): # T is (n x 3)\n",
    "    Y = np.zeros((2,len(T)),dtype=float) # (n x 2)\n",
    "    l,w,t = 100,4,2\n",
    "    T1,T2,T3 = T[:,0],T[:,1],T[:,2] # Python is indexed from 0\n",
    "    if compute_flags[0]: # compute D. x^2 is \"x**2\" in Python\n",
    "        Y[0] = 4*l**3/(T1*w*t)*np.sqrt(T2**2/t**4+T3**2/w**4)\n",
    "    if compute_flags[1]: # compute S\n",
    "        Y[1] = 600*(T2/(w*t**2)+T3/(w**2*t))\n",
    "    return Y\n",
    "true_measure = qp.Gaussian(\n",
    "    sampler = qp.DigitalNetB2(dimension=3,seed=7),\n",
    "    mean = [2.9e7,500,1000],\n",
    "    covariance = np.diag([(1.45e6)**2,(100)**2,(100)**2]))\n",
    "integrand = qp.CustomFun(true_measure,\n",
    "    g = cantilever_beam_function,\n",
    "    dimension_indv = 2)\n",
    "qmc_stop_crit = qp.CubQMCNetG(integrand,\n",
    "    abs_tol = 1e-3,\n",
    "    rel_tol = 1e-6)\n",
    "solution,data = qmc_stop_crit.integrate()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data',header=None)\n",
    "df.columns = ['Age','1900 Year','Axillary Nodes','Survival Status']\n",
    "df.loc[df['Survival Status']==2,'Survival Status'] = 0\n",
    "x,y = df[['Age','1900 Year','Axillary Nodes']],df['Survival Status']\n",
    "xt,xv,yt,yv = train_test_split(x,y,test_size=.33,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  1900 Year  Axillary Nodes  Survival Status\n",
      "0   30         64               1                1\n",
      "1   30         62               3                1\n",
      "2   30         65               0                1\n",
      "3   31         59               2                1\n",
      "4   31         65               4                1 \n",
      "\n",
      "              Age   1900 Year  Axillary Nodes\n",
      "count  306.000000  306.000000      306.000000\n",
      "mean    52.457516   62.852941        4.026144\n",
      "std     10.803452    3.249405        7.189654\n",
      "min     30.000000   58.000000        0.000000\n",
      "25%     44.000000   60.000000        0.000000\n",
      "50%     52.000000   63.000000        1.000000\n",
      "75%     60.750000   65.750000        4.000000\n",
      "max     83.000000   69.000000       52.000000 \n",
      "\n",
      "count     306\n",
      "unique      2\n",
      "top         1\n",
      "freq      225\n",
      "Name: Survival Status, dtype: object\n",
      "\n",
      "train samples: 205 test samples: 101\n",
      "\n",
      "train positives 151   train negatives: 54\n",
      " test positives 74    test negatives: 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>1900 Year</th>\n",
       "      <th>Axillary Nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>50</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  1900 Year  Axillary Nodes\n",
       "46    41         58               0\n",
       "199   57         64               1\n",
       "115   49         64              10\n",
       "128   50         61               0\n",
       "249   63         63               0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head(),'\\n')\n",
    "print(df[['Age','1900 Year','Axillary Nodes']].describe(),'\\n')\n",
    "print(df['Survival Status'].astype(str).describe())\n",
    "print('\\ntrain samples: %d test samples: %d\\n'%(len(xt),len(xv)))\n",
    "print('train positives %d   train negatives: %d'%(np.sum(yt==1),np.sum(yt==0)))\n",
    "print(' test positives %d    test negatives: %d'%(np.sum(yv==1),np.sum(yv==0)))\n",
    "xt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data (Data)\n",
      "    solution        [-0.128  0.084 -0.091  0.09 ]\n",
      "    comb_bound_low  [-0.198  0.069 -0.14   0.074]\n",
      "    comb_bound_high [-0.105  0.129 -0.075  0.138]\n",
      "    comb_bound_diff [0.092 0.06  0.065 0.065]\n",
      "    comb_flags      [ True  True  True  True]\n",
      "    n_total         2^(17)\n",
      "    n               [[  1024   1024   2048 131072]\n",
      "                     [  1024   1024   2048 131072]]\n",
      "    time_integrate  0.397\n",
      "CubQMCNetG (AbstractStoppingCriterion)\n",
      "    abs_tol         0.100\n",
      "    rel_tol         2^(-1)\n",
      "    n_init          2^(10)\n",
      "    n_limit         2^(18)\n",
      "BayesianLRCoeffs (AbstractIntegrand)\n",
      "Gaussian (AbstractTrueMeasure)\n",
      "    mean            0\n",
      "    covariance      5\n",
      "    decomp_type     PCA\n",
      "DigitalNetB2 (AbstractLDDiscreteDistribution)\n",
      "    d               2^(2)\n",
      "    replications    1\n",
      "    randomize       LMS DS\n",
      "    gen_mats_source joe_kuo.6.21201.txt\n",
      "    order           RADICAL INVERSE\n",
      "    t               63\n",
      "    alpha           1\n",
      "    n_limit         2^(32)\n",
      "    entropy         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nData (Data)\\nsolution        [-0.128  0.084 -0.091  0.09 ]\\ncomb_bound_low  [-0.198  0.069 -0.14   0.074]\\ncomb_bound_high [-0.105  0.129 -0.075  0.138]\\ncomb_bound_diff [0.092 0.06  0.065 0.065]\\ncomb_flags      [ True  True  True  True]\\nn_total         2^(17)\\nn               [[  1024   1024   2048 131072]\\n                    [  1024   1024   2048 131072]]\\ntime_integrate  0.351\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blr = qp.BayesianLRCoeffs(\n",
    "    sampler = qp.DigitalNetB2(4,seed=1),\n",
    "    feature_array = xt, # np.ndarray of shape (n,d-1)\n",
    "    response_vector = yt, # np.ndarray of shape (n,)\n",
    "    prior_mean = 0, # normal prior mean = (0,0,...,0)\n",
    "    prior_covariance = 5) # normal prior covariance = 5I\n",
    "qmc_sc = qp.CubQMCNetG(blr,\n",
    "    abs_tol = .1,\n",
    "    rel_tol = .5,\n",
    "    error_fun = \"BOTH\",\n",
    "    n_limit=2**18)\n",
    "blr_coefs,blr_data = qmc_sc.integrate()\n",
    "print(blr_data)\n",
    "\"\"\"\n",
    "Data (Data)\n",
    "solution        [-0.128  0.084 -0.091  0.09 ]\n",
    "comb_bound_low  [-0.198  0.069 -0.14   0.074]\n",
    "comb_bound_high [-0.105  0.129 -0.075  0.138]\n",
    "comb_bound_diff [0.092 0.06  0.065 0.065]\n",
    "comb_flags      [ True  True  True  True]\n",
    "n_total         2^(17)\n",
    "n               [[  1024   1024   2048 131072]\n",
    "                    [  1024   1024   2048 131072]]\n",
    "time_integrate  0.351\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Age  1900 Year  Axillary Nodes  Intercept  \\\n",
      "method                                                                    \n",
      "Elastic-Net \\lambda=0.0 -0.012279   0.034401       -0.115153   0.001990   \n",
      "Elastic-Net \\lambda=0.5 -0.012041   0.034170       -0.114770   0.002025   \n",
      "Elastic-Net \\lambda=1.0 -0.011803   0.033940       -0.114387   0.002061   \n",
      "Bayesian                -0.128270   0.083826       -0.090906   0.089903   \n",
      "\n",
      "                         Accuracy  Precision    Recall  \n",
      "method                                                  \n",
      "Elastic-Net \\lambda=0.0  0.742574   0.766667  0.932432  \n",
      "Elastic-Net \\lambda=0.5  0.742574   0.766667  0.932432  \n",
      "Elastic-Net \\lambda=1.0  0.742574   0.766667  0.932432  \n",
      "Bayesian                 0.326733   1.000000  0.081081  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def metrics(y,yhat):\n",
    "    y,yhat = np.array(y),np.array(yhat)\n",
    "    tp = np.sum((y==1)*(yhat==1))\n",
    "    tn = np.sum((y==0)*(yhat==0))\n",
    "    fp = np.sum((y==0)*(yhat==1))\n",
    "    fn = np.sum((y==1)*(yhat==0))\n",
    "    accuracy = (tp+tn)/(len(y))\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    return [accuracy,precision,recall]\n",
    "\n",
    "results = pd.DataFrame({name:[] for name in ['method','Age','1900 Year','Axillary Nodes','Intercept','Accuracy','Precision','Recall']})\n",
    "for i,l1_ratio in enumerate([0,.5,1]):\n",
    "    lr = LogisticRegression(random_state=7,penalty=\"elasticnet\",solver='saga',l1_ratio=l1_ratio).fit(xt,yt)\n",
    "    results.loc[i] = [r'Elastic-Net \\lambda=%.1f'%l1_ratio]+lr.coef_.squeeze().tolist()+[lr.intercept_.item()]+metrics(yv,lr.predict(xv))\n",
    "\n",
    "blr_predict = lambda x: 1/(1+np.exp(-np.array(x)@blr_coefs[:-1]-blr_coefs[-1]))>=.5\n",
    "blr_train_accuracy = np.mean(blr_predict(xt)==yt)\n",
    "blr_test_accuracy = np.mean(blr_predict(xv)==yv)\n",
    "results.loc[len(results)] = ['Bayesian']+blr_coefs.squeeze().tolist()+metrics(yv,blr_predict(xv))\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',FutureWarning)\n",
    "results.set_index('method',inplace=True)\n",
    "print(results.head())\n",
    "#root: results.to_latex(root+'lr_table.tex',formatters={'%s'%tt:lambda v:'%.1f'%(100*v) for tt in ['accuracy','precision','recall']},float_format=\"%.2e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ishigami Sensitivity Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data (Data)\n",
      "    solution        [[0.315 0.421 0.004 0.735 0.558 0.419]\n",
      "                     [0.565 0.444 0.244 0.987 0.558 0.688]]\n",
      "    comb_bound_low  [[0.293 0.409 0.    0.706 0.534 0.399]\n",
      "                     [0.541 0.435 0.234 0.974 0.539 0.667]]\n",
      "    comb_bound_high [[0.336 0.432 0.008 0.765 0.582 0.438]\n",
      "                     [0.59  0.452 0.253 1.    0.577 0.708]]\n",
      "    comb_bound_diff [[0.043 0.023 0.008 0.059 0.047 0.039]\n",
      "                     [0.049 0.017 0.02  0.026 0.038 0.042]]\n",
      "    comb_flags      [[ True  True  True  True  True  True]\n",
      "                     [ True  True  True  True  True  True]]\n",
      "    n_total         2^(10)\n",
      "    n               [[[1024 1024 1024 1024 1024 1024]\n",
      "                      [1024 1024 1024 1024 1024 1024]\n",
      "                      [1024 1024 1024 1024 1024 1024]]\n",
      "                    \n",
      "                     [[1024 1024 1024 1024 1024 1024]\n",
      "                      [1024 1024 1024 1024 1024 1024]\n",
      "                      [1024 1024 1024 1024 1024 1024]]]\n",
      "    time_integrate  0.010\n",
      "CubQMCNetG (AbstractStoppingCriterion)\n",
      "    abs_tol         0.050\n",
      "    rel_tol         0\n",
      "    n_init          2^(10)\n",
      "    n_limit         2^(35)\n",
      "SensitivityIndices (AbstractIntegrand)\n",
      "    indices         [[ True False False]\n",
      "                     [False  True False]\n",
      "                     [False False  True]\n",
      "                     [ True  True False]\n",
      "                     [ True False  True]\n",
      "                     [False  True  True]]\n",
      "Uniform (AbstractTrueMeasure)\n",
      "    lower_bound     -3.142\n",
      "    upper_bound     3.142\n",
      "DigitalNetB2 (AbstractLDDiscreteDistribution)\n",
      "    d               3\n",
      "    replications    1\n",
      "    randomize       LMS DS\n",
      "    gen_mats_source joe_kuo.6.21201.txt\n",
      "    order           RADICAL INVERSE\n",
      "    t               63\n",
      "    alpha           1\n",
      "    n_limit         2^(32)\n",
      "    entropy         7\n",
      "\n",
      "Approx took 0.0 sec and n = 2^(10)\n",
      "\t si_closed: [0.31495301 0.42054985 0.00403061 0.73545156 0.5580266  0.41868287]\n",
      "\t si_total: [0.56524058 0.4435145  0.24364672 0.98722305 0.557734   0.68753131]\n",
      "\t ci_comb_low_closed: [0.2934895  0.4092381  0.         0.70577578 0.53435058 0.39922204]\n",
      "\t ci_comb_high_closed: [0.33641652 0.4318616  0.00806122 0.76512734 0.58170261 0.4381437 ]\n",
      "\t ci_comb_low_total: [0.54066449 0.43508219 0.23389506 0.9744461  0.53864679 0.66669245]\n",
      "\t ci_comb_high_total: [0.58981667 0.45194681 0.25339839 1.         0.57682122 0.70837017]\n"
     ]
    }
   ],
   "source": [
    "a,b = 7,0.1\n",
    "dnb2 = qp.DigitalNetB2(3,seed=7)\n",
    "ishigami = qp.Ishigami(dnb2,a,b)\n",
    "idxs = np.array([\n",
    "    [True,False,False],\n",
    "    [False,True,False],\n",
    "    [False,False,True],\n",
    "    [True,True,False],\n",
    "    [True,False,True],\n",
    "    [False,True,True]],dtype=bool)\n",
    "ishigami_si = qp.SensitivityIndices(ishigami,idxs)\n",
    "qmc_algo = qp.CubQMCNetG(ishigami_si,abs_tol=.05)\n",
    "solution,data = qmc_algo.integrate()\n",
    "print(data)\n",
    "si_closed = solution[0].squeeze()\n",
    "si_total = solution[1].squeeze()\n",
    "ci_comb_low_closed = data.comb_bound_low[0].squeeze()\n",
    "ci_comb_high_closed = data.comb_bound_high[0].squeeze()\n",
    "ci_comb_low_total = data.comb_bound_low[1].squeeze()\n",
    "ci_comb_high_total = data.comb_bound_high[1].squeeze()\n",
    "print(\"\\nApprox took %.1f sec and n = 2^(%d)\"%\n",
    "    (data.time_integrate,np.log2(data.n_total)))\n",
    "print('\\t si_closed:',si_closed)\n",
    "print('\\t si_total:',si_total)\n",
    "print('\\t ci_comb_low_closed:',ci_comb_low_closed)\n",
    "print('\\t ci_comb_high_closed:',ci_comb_high_closed)\n",
    "print('\\t ci_comb_low_total:',ci_comb_low_total)\n",
    "print('\\t ci_comb_high_total:',ci_comb_high_total)\n",
    "\n",
    "true_indices = qp.Ishigami._exact_sensitivity_indices(idxs,a,b)\n",
    "si_closed_true = true_indices[0]\n",
    "si_total_true = true_indices[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classifier Sensitiviy Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.0%\n",
      "samples: 2^(15)\n",
      "time: 7.1e-01\n",
      "indices:\n",
      "[[ True False False False]\n",
      " [False  True False False]\n",
      " [False False  True False]\n",
      " [False False False  True]\n",
      " [ True  True False False]\n",
      " [ True False  True False]\n",
      " [ True False False  True]\n",
      " [False  True  True False]\n",
      " [False  True False  True]\n",
      " [False False  True  True]\n",
      " [ True  True  True False]\n",
      " [ True  True False  True]\n",
      " [ True False  True  True]\n",
      " [False  True  True  True]]\n",
      "\n",
      "Closed Indices\n",
      "           setosa  versicolor  virginica\n",
      "[0]      0.001323    0.068645   0.077325\n",
      "[1]      0.063749    0.026565   0.004784\n",
      "[2]      0.713825    0.325072   0.497800\n",
      "[3]      0.052967    0.025579   0.120317\n",
      "[0 1]    0.063925    0.091300   0.085151\n",
      "[0 2]    0.715316    0.460314   0.637738\n",
      "[0 3]    0.053469    0.092601   0.205639\n",
      "[1 2]    0.841655    0.431035   0.513277\n",
      "[1 3]    0.110739    0.039410   0.131264\n",
      "[2 3]    0.822910    0.583282   0.703142\n",
      "[0 1 2]  0.843726    0.570076   0.658272\n",
      "[0 1 3]  0.112798    0.104804   0.215817\n",
      "[0 2 3]  0.825330    0.815263   0.945267\n",
      "[1 2 3]  0.995864    0.739588   0.728499\n",
      "\n",
      "Total Indices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>0.132343</td>\n",
       "      <td>6.374860</td>\n",
       "      <td>71.382498</td>\n",
       "      <td>5.296674</td>\n",
       "      <td>83.186375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>6.864536</td>\n",
       "      <td>2.656530</td>\n",
       "      <td>32.507230</td>\n",
       "      <td>2.557911</td>\n",
       "      <td>44.586208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>7.732521</td>\n",
       "      <td>0.478364</td>\n",
       "      <td>49.779978</td>\n",
       "      <td>12.031725</td>\n",
       "      <td>70.022587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "setosa               0.132343          6.374860          71.382498   \n",
       "versicolor           6.864536          2.656530          32.507230   \n",
       "virginica            7.732521          0.478364          49.779978   \n",
       "\n",
       "            petal width (cm)        sum  \n",
       "setosa              5.296674  83.186375  \n",
       "versicolor          2.557911  44.586208  \n",
       "virginica          12.031725  70.022587  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "data = load_iris()\n",
    "feature_names = data[\"feature_names\"]\n",
    "feature_names = [fn.replace('sepal ','S')\\\n",
    "    .replace('length ','L')\\\n",
    "    .replace('petal ','P')\\\n",
    "    .replace('width ','W')\\\n",
    "    .replace('(cm)','') for fn in feature_names]\n",
    "target_names = data[\"target_names\"]\n",
    "xt,xv,yt,yv = train_test_split(data[\"data\"],data[\"target\"],\n",
    "    test_size = 1/3,\n",
    "    random_state = 7)\n",
    "mlpc = MLPClassifier(random_state=7,max_iter=1024).fit(xt,yt)\n",
    "yhat = mlpc.predict(xv)\n",
    "print(\"accuracy: %.1f%%\"%(100*(yv==yhat).mean()))\n",
    "# accuracy: 98.0%\n",
    "sampler = qp.DigitalNetB2(4,seed=7)\n",
    "true_measure =  qp.Uniform(sampler,\n",
    "    lower_bound = xt.min(0),\n",
    "    upper_bound = xt.max(0))\n",
    "fun = qp.CustomFun(\n",
    "    true_measure = true_measure,\n",
    "    g = lambda x: mlpc.predict_proba(x).T,\n",
    "    dimension_indv = 3)\n",
    "si_fun = qp.SensitivityIndices(fun,indices=\"all\")\n",
    "qmc_algo = qp.CubQMCNetG(si_fun,abs_tol=.005)\n",
    "nn_sis,nn_sis_data = qmc_algo.integrate()\n",
    "nn_sis.shape\n",
    "\"\"\"\n",
    "(2, 14, 3)\n",
    "\"\"\"\n",
    "#print(nn_sis_data.flags_indv.shape)\n",
    "#print(nn_sis_data.flags_comb.shape)\n",
    "print('samples: 2^(%d)'%np.log2(nn_sis_data.n_total))\n",
    "print('time: %.1e'%nn_sis_data.time_integrate)\n",
    "print('indices:\\n%s'%nn_sis_data.integrand.indices)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_closed = pd.DataFrame(nn_sis[0],columns=target_names,index=[str(np.where(idx)[0]) for idx in nn_sis_data.integrand.indices])\n",
    "print('\\nClosed Indices')\n",
    "print(df_closed)\n",
    "df_total = pd.DataFrame(nn_sis[1],columns=target_names,index=[str(np.where(idx)[0]) for idx in nn_sis_data.integrand.indices])\n",
    "print('\\nTotal Indices')\n",
    "df_closed_singletons = df_closed.loc[['[%d]'%i for i in range(4)]].T\n",
    "df_closed_singletons['sum singletons'] = df_closed_singletons[['[%d]'%i for i in range(4)]].sum(1)\n",
    "df_closed_singletons.columns = data['feature_names']+['sum']\n",
    "df_closed_singletons = df_closed_singletons*100\n",
    "df_closed_singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qmcpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
