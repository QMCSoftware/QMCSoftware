{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37dc281d",
   "metadata": {},
   "source": [
    "# [ParslFest 2025](https://parsl-project.org/parslfest/parslfest2025.html)\n",
    "\n",
    "# [Accelerating QMCpy Notebook Tests with Parsl](https://www.figma.com/slides/k7EUosssNluMihkYTLuh1F/Parsl-Testbook-Speedup?node-id=1-37&t=WnKcu2QYO8JXvtpP-0)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QMCSoftware/QMCSoftware/blob/develop/demos/talk_paper_demos/parsl_fest_2025/parsl_fest_2025.ipynb)\n",
    "\n",
    "Joshua Herman, Brandon Sharp, and Sou-Cheng Choi, QMCPy Developers\n",
    "\n",
    "Aug 28 -- 29, 2025\n",
    "\n",
    "Updated: Dec 1, 2025\n",
    "\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "* testbook : `pip install testbook==0.4.2`\n",
    "* Parsl: `pip install parsl==2025.7.28`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d41c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import parsl as pl\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -q parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ff15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import parsl as pl\n",
    "\n",
    "# Ensure the path to the booktests directory is included (robust finder)\n",
    "def _find_repo_root(start=os.getcwd()):\n",
    "    cur = start\n",
    "    while True:\n",
    "        if os.path.exists(os.path.join(cur, 'pyproject.toml')):\n",
    "            return cur\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            raise FileNotFoundError('repo root not found')\n",
    "        cur = parent\n",
    "\n",
    "sys.path.append(os.path.join(_find_repo_root(), 'test', 'booktests'))\n",
    "\n",
    "# Configuration flags\n",
    "force_compute = True\n",
    "is_debug = True\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b428f",
   "metadata": {},
   "source": [
    "## 2. Parsl\n",
    "\n",
    "1. Install and Configure Parsl\n",
    "2. Run the tests in parallel with Parsl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084b195",
   "metadata": {},
   "source": [
    "### 2.1 Configure Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5b9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from parsl.config import Config\n",
    "from parsl.executors import HighThroughputExecutor, ThreadPoolExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# Read max workers from environment if provided, else default to cpu_count()-1\n",
    "try:\n",
    "    max_workers = int(os.environ.get('PARSL_MAX_WORKERS'))\n",
    "except Exception:\n",
    "    max_workers = max(1, (os.cpu_count() or 2) - 1)\n",
    "\n",
    "# Choose executor based on platform to avoid macOS spawn/interchange issues\n",
    "if platform.system().lower() == \"darwin\":\n",
    "    # macOS: use threads to avoid subprocess/interchange problems\n",
    "    exec_obj = ThreadPoolExecutor(max_threads=max_workers, label=\"local_threads\")\n",
    "else:\n",
    "    # Other platforms: use HTEX with explicit interchange command\n",
    "    interchange_cmd = [sys.executable, \"-m\", \"parsl.executors.high_throughput.interchange\"]\n",
    "    exec_obj = HighThroughputExecutor(\n",
    "        label=\"htex_local\",\n",
    "        max_workers_per_node=max_workers,\n",
    "        provider=LocalProvider(init_blocks=1, max_blocks=1),\n",
    "        interchange_launch_cmd=interchange_cmd,\n",
    "    )\n",
    "\n",
    "config = Config(executors=[exec_obj])\n",
    "\n",
    "# Ensure clean state: clear any existing Parsl config from previous runs\n",
    "pl.clear()\n",
    "\n",
    "# Now load the config\n",
    "pl.load(config)\n",
    "\n",
    "# print worker info\n",
    "if hasattr(exec_obj, \"max_workers_per_node\"):\n",
    "    workers_info = exec_obj.max_workers_per_node\n",
    "elif hasattr(exec_obj, \"max_threads\"):\n",
    "    workers_info = exec_obj.max_threads\n",
    "else:\n",
    "    workers_info = max_workers\n",
    "\n",
    "print(f\"Parsl loaded with {workers_info} workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161c897",
   "metadata": {},
   "source": [
    "### 2.2 Create a Parsl Test Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl_test_runner\n",
    "import inspect\n",
    "\n",
    "# See only functions\n",
    "print(\"Functions:\")\n",
    "functions = inspect.getmembers(parsl_test_runner, inspect.isfunction)\n",
    "for name, func in functions:\n",
    "    print(f\"- {name}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Get help on specific function\n",
    "print(\"Help for execute_parallel_tests:\")\n",
    "help(parsl_test_runner.execute_parallel_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Parsl configuration\n",
    "print(f\"Max workers configured: {max_workers}\")\n",
    "print(f\"Active Parsl DFK: {pl.dfk()}\")\n",
    "print(f\"Executors: {[executor.label for executor in pl.dfk().executors.values()]}\")\n",
    "if hasattr(config, 'executors'):\n",
    "    for executor in config.executors:\n",
    "        if hasattr(executor, 'max_workers_per_node'):\n",
    "            print(f\"Executor '{executor.label}' max_workers_per_node: {executor.max_workers_per_node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ee440",
   "metadata": {},
   "source": [
    "### 2.3 Run the Notebooks in Parallel with Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "execution_id = str(uuid.uuid4())[:8]\n",
    "print(f\"=== EXECUTION ID: {execution_id} ===\")\n",
    "print(f\"Starting parallel test execution with {max_workers} workers...\")\n",
    "\n",
    "par_fname = os.path.join(output_dir, f\"parallel_times_{max_workers}.csv\")\n",
    "par_output = os.path.join(output_dir, f\"parallel_output_{max_workers}.txt\")\n",
    "is_linux = sys.platform.startswith(\"linux\")\n",
    "\n",
    "if (not os.path.exists(par_fname)) or force_compute:\n",
    "    repo_root = _find_repo_root()\n",
    "    \n",
    "    if is_debug:\n",
    "        tests = \"tb_quickstart tb_qmcpy_intro tb_lattice_random_generator\"\n",
    "        cmd = [\"make\", \"booktests_parallel_no_docker\", f\"TESTS={tests}\"]\n",
    "    else:\n",
    "        cmd = [\"make\" if not is_linux else \"make -j1\", \"booktests_parallel_no_docker\"]\n",
    "    if is_linux:\n",
    "        cmd = [\"taskset\", \"-c\", \"0\"] + cmd\n",
    "    \n",
    "    # Propagate PARSL_MAX_WORKERS environment variable to subprocess\n",
    "    env = os.environ.copy()\n",
    "    env['PARSL_MAX_WORKERS'] = str(max_workers)\n",
    "    \n",
    "    with open(par_output, 'wb') as out_f:\n",
    "        try:\n",
    "            subprocess.run(cmd, cwd=repo_root, stdout=out_f, stderr=subprocess.STDOUT, check=True, env=env)\n",
    "        except subprocess.CalledProcessError:\n",
    "            pass\n",
    "    \n",
    "    # parse parallel time from output (sum of individual test times, not wall-clock)\n",
    "    with open(par_output, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "        match = re.search(r\"Total test time: ([\\d\\.]+)s\", text)\n",
    "        if match:\n",
    "            parallel_time = float(match.group(1))\n",
    "        else:\n",
    "            parallel_time = 0.0\n",
    "\n",
    "    print(f\"\\n=== RESULTS FOR EXECUTION {execution_id} ===\")\n",
    "    print(f\"Parallel time: {parallel_time:.2f} seconds\")\n",
    "\n",
    "    with open(par_fname, \"w\") as f:\n",
    "        _ = f.write(f\"workers,time\\n\")\n",
    "        _ = f.write(f\"{max_workers},{parallel_time:.2f}\\n\")\n",
    "    \n",
    "    print(f\"=== END EXECUTION {execution_id} ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date\n",
    "!ls -ltr output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d24aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if platform.system().lower() == 'linux':\n",
    "    !uname -a\n",
    "    !nproc --all\n",
    "    !awk '/MemTotal/ {printf \"%.2f GB\\n\", $2/1024/1024}' /proc/meminfo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qmcpy",
   "language": "python",
   "name": "qmcpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
