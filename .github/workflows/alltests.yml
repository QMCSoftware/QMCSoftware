name: All Tests
on: [push]


jobs:
  #============================================================
  # 3 Test Jobs on 3 OSes: Windows, macOS, Ubuntu
  #============================================================
  tests:
    name: All Tests on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
        matrix:  # https://docs.github.com/en/actions/reference/runners/github-hosted-runners
            os: ["windows-latest", "macos-latest", "ubuntu-latest"] 
    steps:
      - uses: actions/checkout@v4
      - uses: conda-incubator/setup-miniconda@v3
        with:
          miniconda-version: "latest"
          auto-activate-base: true
          conda-remove-defaults: true
          use-only-tar-bz2: true
      
      # -----------------------------------------------------------
      # Clean old coverage files
      # -----------------------------------------------------------
      - name: Remove old coverage data (Unix)
        if: runner.os != 'Windows'
        run: |
          rm -f .coverage* coverage.json || true

      - name: Remove old coverage data (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          Remove-Item -Path .coverage* -Force -ErrorAction SilentlyContinue -Confirm:$false
          Remove-Item -Path coverage.json -Force -ErrorAction SilentlyContinue -Confirm:$false
      # -----------------------------------------------------------
      # Add 12GB swap, i.e., virtual memory (OS-specific)
      # -----------------------------------------------------------
      - name: Add 12GB swap (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo fallocate -l 12G /swapfile
          sudo chmod 600 /swapfile
          sudo mkswap /swapfile
          sudo swapon /swapfile
          free -h
      - name: Add 12GB swap (macOS)
        if: runner.os == 'macOS'
        run: |
          # Create and mount a temporary swapfile
          sudo mkfile 12g /private/var/vm/tempswapfile
          sudo chmod 600 /private/var/vm/tempswapfile
      - name: Configure pagefile (Windows) via CIM (12GB)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          $drive    = "D:"
          $initialMB = 12288
          $maxMB     = 12288
          $pagefile  = "$drive\pagefile.sys"
          Write-Host "Configuring pagefile: $pagefile (Initial=${initialMB}MB, Max=${maxMB}MB)"
          # Disable automatic management
          $cs = Get-CimInstance Win32_ComputerSystem
          if ($cs.AutomaticManagedPagefile) {
            Set-CimInstance -InputObject $cs -Property @{ AutomaticManagedPagefile = $false } | Out-Null
          }
          # Create or update the pagefile setting
          $escaped = $pagefile.Replace('\','\\')
          $pfs = Get-CimInstance Win32_PageFileSetting -Filter "Name='$escaped'" -ErrorAction SilentlyContinue
          if ($null -eq $pfs) {
            New-CimInstance -ClassName Win32_PageFileSetting -Property @{
              Name        = $pagefile
              InitialSize = $initialMB
              MaximumSize = $maxMB
            } | Out-Null
          } else {
            Set-CimInstance -InputObject $pfs -Property @{
              InitialSize = $initialMB
              MaximumSize = $maxMB
            } | Out-Null
          }
          "=== Pagefile settings ==="
          Get-CimInstance Win32_PageFileSetting | Format-Table Name,InitialSize,MaximumSize -Auto
      # -----------------------------------------------------------
      # Free disk + conda cache early (OS-specific)
      # -----------------------------------------------------------
      - name: Free space (Linux)
        if: runner.os == 'Linux'
        run: |
          df -h
          sudo apt-get clean
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache
          conda clean --all --yes
          pip cache purge || true
          df -h
      - name: Free space (macOS)
        if: runner.os == 'macOS'
        run: |
          df -h
          conda clean --all --yes
          pip cache purge || true
          df -h
      - name: Free space (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          Get-Volume | Select-Object DriveLetter, Size, SizeRemaining | Format-Table
          conda clean --all --yes || true
          pip cache purge || true
          Get-Volume | Select-Object DriveLetter, Size, SizeRemaining | Format-Table
      # -----------------------------------------------------------
      # Show resources (OS-specific)
      # -----------------------------------------------------------
      - name: Show runner resources
        if: runner.os != 'Windows'
        run: |
          echo "CPUs: $(nproc || sysctl -n hw.ncpu)"
          free -h || vm_stat
          df -h
      - name: Show runner resources
        if: runner.os == 'Windows'
        run: |
          # Check current pagefile settings
          Get-WmiObject Win32_PageFileUsage | Select-Object Name, AllocatedBaseSize
          # Display system memory info
          Get-ComputerInfo -Property CsTotalPhysicalMemory
      # -----------------------------------------------------------
      # Install Python dependencies
      # -----------------------------------------------------------
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/pip/wheels
            ~/Library/Caches/pip
            ~/Library/Caches/pip/wheels
            ~\AppData\Local\pip\Cache
            ~\AppData\Local\pip\Cache\wheels
          key: ${{ runner.os }}-pip-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Cache wheel files
        uses: actions/cache@v4
        with:
          path: ./.wheels
          key: ${{ runner.os }}-wheels-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-wheels-
          
      - name: Build and cache wheels (Linux)
        if: runner.os == 'Linux'
        run: |
          python -m pip wheel -w ./.wheels .[test,test_torch,test_gpytorch,test_botorch,test_umbridge] || true
      - name: Install Python dependencies (Linux)
        if: runner.os == 'Linux'
        run: |
          pip install --find-links ./.wheels -e ".[test,test_torch,test_gpytorch,test_botorch,test_umbridge]"
      - name: Build and cache wheels (macOS)
        if: runner.os == 'macOS'
        run: |
          python -m pip wheel -w ./.wheels .[test,test_torch,test_gpytorch,test_botorch] || true
      - name: Install Python dependencies (macOS)
        if: runner.os == 'macOS'
        run: |
          pip install --find-links ./.wheels -e ".[test,test_torch,test_gpytorch,test_botorch]"
      - name: Build and cache wheels (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          python -m pip wheel -w ./.wheels .[test,test_torch,test_gpytorch,test_botorch] || Write-Host 'wheel build step completed'
      - name: Install Python dependencies (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          pip install --find-links ./.wheels -e '.[test,test_torch,test_gpytorch,test_botorch]'
      # -----------------------------------------------------------
      # Install minimal LaTeX required by Jupyter notebooks (OS-specific)
      # -----------------------------------------------------------
      - name: Install minimal LaTeX (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt update
          sudo apt install -y texlive-latex-base texlive-latex-extra texlive-latex-recommended latexmk dvipng cm-super
      - name: Install minimal LaTeX (macOS)
        if: runner.os == 'macOS'
        run: |
          brew install --cask basictex
          eval "$(/usr/libexec/path_helper)"
          sudo tlmgr update --self
          sudo tlmgr install latexmk dvipng collection-fontsrecommended type1cm
      - name: Cache MiKTeX (Windows)
        if: runner.os == 'Windows'
        uses: actions/cache@v4
        with:
          path: C:\Program Files\MiKTeX
          key: ${{ runner.os }}-miktex-${{ hashFiles('.github/workflows/alltests.yml') }}
          restore-keys: |
            ${{ runner.os }}-miktex-
          
      - name: Install MiKTeX (retry if needed)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          choco install miktex --no-progress --limit-output -y || choco install miktex --no-progress --limit-output -y
          # Put MiKTeX on PATH for all subsequent steps
          echo "C:\Program Files\MiKTeX\miktex\bin\x64" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
          $env:PATH = "C:\Program Files\MiKTeX\miktex\bin\x64;$env:PATH"
      
      - name: Install required MiKTeX packages
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          miktexsetup finish
          mpm --admin --verbose --require=cm,cm-super,cmex10,luxi,times,thailatex,latexmk,dvipng
      
      - name: Update MiKTeX font map
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          initexmf --admin --update-fndb
          initexmf --admin --mkmaps
          
          latex --version
          latexmk -v
          dvipng --version
      
      # -----------------------------------------------------------
      # Run doctests (OS-specific)
      # -----------------------------------------------------------      
      - run: pip freeze
      - run: make doctests_minimal
      - run: make doctests_torch
      - run: make doctests_gpytorch
      - run: make doctests_botorch
      - run: make doctests_markdown
      - name: run umbridge doctests on Linux only
        shell: bash -l {0}
        run: |
          if [ "$RUNNER_OS" == "Linux" ]; then
            make doctests_umbridge
          else
            echo "umbridge doctests only run on Linux"
          fi
      # -----------------------------------------------------------
      # Run unittests for Python source files
      # -----------------------------------------------------------   
      - name: Run unittests (parallel)
        run: make unittests
      
      # -----------------------------------------------------------
      # Free disk + conda cache before booktests (OS-specific)
      # -----------------------------------------------------------
      - name: Free space (Linux)
        if: runner.os == 'Linux'
        run: |
          df -h
          sudo apt-get clean
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache
          docker system prune -af || true
          conda clean --all --yes
          pip cache purge || true
          df -h
      - name: Free space (macOS)
        if: runner.os == 'macOS'
        run: |
          df -h
          conda clean --all --yes
          pip cache purge || true
          df -h
      - name: Free space (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          Get-Volume | Select-Object DriveLetter, Size, SizeRemaining | Format-Table
          conda clean --all --yes || true
          pip cache purge || true
          Get-Volume | Select-Object DriveLetter, Size, SizeRemaining | Format-Table

      # -----------------------------------------------------------
      # Run unittests for Jupyter notebooks (OS-specific)
      # ----------------------------------------------------------- 
      - name: Run booktests (parallel) on Linux/macOS
        if: runner.os != 'Windows'
        shell: bash -l {0}
        run: |
          make booktests_parallel_no_docker    # Parsl not supported on Windows
      - name: Run booktests (parallel) on Windows
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          make booktests_parallel_pytest PYTEST_XDIST="-n 4"

      # -----------------------------------------------------------
      # Display final accumulated coverage from all test stages
      # -----------------------------------------------------------
      - name: Display final coverage report
        if: runner.os != 'Windows'
        run: |
          coverage report -m
          coverage json

      # -----------------------------------------------------------
      # Upload coverage data for later combination
      # -----------------------------------------------------------
      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.os }}
          path: |
            .coverage
            .coverage.*
            coverage.json
          retention-days: 1

  # =============================================================
  # Combine coverage from all OS runners and produce final report
  # =============================================================
  combine-coverage:
    runs-on: ubuntu-latest
    needs: tests  # Wait for 3 test jobs to complete
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install coverage
        run: python -m pip install coverage
      
      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          path: coverage-data
          pattern: coverage-*
      
      - name: Combine coverage and generate reports
        run: |
          # List downloaded artifacts for debugging
          ls -la coverage-data/
          find coverage-data -type f -name '.coverage*' -o -name 'coverage.json'
          # Move all coverage files to current directory
          find coverage-data -name '.coverage*' -exec cp {} . \;
          # List coverage files to combine
          ls -la .coverage*
          # Combine coverage data from all runners
          python -m coverage combine --keep
          # Generate reports
          python -m coverage report -m
          python -m coverage xml -o coverage.xml
          python -m coverage html -d coverage_html
      
      - name: Upload combined coverage HTML report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-html
          path: coverage_html
      
      - name: Upload coverage XML for external tools
        uses: actions/upload-artifact@v4
        with:
          name: coverage-xml
          path: coverage.xml

# For success reports, see https://github.com/QMCSoftware/QMCSoftware/actions?query=is%3Asuccess+workflow%3AAll+Tests